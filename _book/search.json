[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción al análisis de datos con R",
    "section": "",
    "text": "El objetivo de este ebook es brindarle al lector una introducción amigable pero completa sobre el manejo básico de R para el análisis de datos. Se presupone que quien utilice este manual desde el comienzo, no tenga conocimientos previos de R o de programación, por tanto, podrá utilizar esta herramienta para dar sus primeros pasos en el mundo de la ciencia de datos.\nTambién puede ser de utilidad para quien tenga experiencia, en la medida que cada tanto es de utilidad repasar los conceptos fundamentales, especialmente si hace tiempo que no realizamos determinada tarea, o si nunca se tuvo la necesidad de encarar determinado proyecto, por ejemplo, una Shiny App.\nEl libro se divide en 7 capítulos:\n\nIntroducción a R, funciones y RStudio\nImportación de datos\nEstructura de dataframes\nAnálisis de datos con R\nManipulación de datos\nVisualización\nPróximos pasos\n\n\n\n\n\n\n\n\n\nSoy un analista de datos con experiencia en proyectos de analytics y machine learning aplicado a negocios. Actualmente me desempeño como analista de datos senior en el Instituto Nacional de Estadística y he colaborado en el desarrollo de modelos predictivos para la consultora BCS y en la elaboración de dashboards como consultor independiente. He sido docente de Python, R y Power BI en Instituto CPE durante cuatro años, donde también me desempeño como coordinador de proyectos. Finalmente, también fui docente de desarrollo web para Plan Ceibal."
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1  Introducción",
    "section": "",
    "text": "Para ver más sobre la relación de R y Python ir a este artículo.↩︎\nVer artículo: La santa trinidad del análisis de datos↩︎"
  },
  {
    "objectID": "chapters/import.html",
    "href": "chapters/import.html",
    "title": "2  Importación de datos",
    "section": "",
    "text": "Cuando trabajamos con archivos de texto plano, lo mejor que podemos hacer cuando pensamos en importarlo, es abrirlo con un bloc de notas (en la medida que el tamaño lo permita).\nLa función más elemental para importar archivos de texto plano es read.table. Esta función tiene la particularidad que prácticamente no toma ningun valor por defecto en sus parámetros y hay que rellenarlos todos de modo de generar una importación.\n\ndata <- read.table(\"../data/courseid_3282_participants.csv\")\ndata\n\nLa sentencia ejecutada anteriormente da el siguiente error:\n\nError in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 2 did not have 3 elements\n\nEsto ocurre porque read.table no sabe qué hacer en el caso de que una fila no contenga el mismo número de elementos que el resto. Para solucionar esto podemos agregar el parámetro que lo aclare.\n\ndata <- read.table(\"../data/courseid_3282_participants.csv\", fill = NA)\n\n\n\n\n\n\nV1\nV2\nV3\n\n\n\n\nNombre,Apellido(s),“Dirección\nde\ncorreo”\n\n\nCECILIA,CARPENA,mcarpena@msp.gub.uy\n\n\n\n\nMarines,FIGUEROA,mfigueroa@msp.gub.uy\n\n\n\n\nLUCA,AICARDI,maicardi@msp.gub.uy\n\n\n\n\nMARCELA,CASTRO,mfcastro@msp.gub.uy\n\n\n\n\nMARIA,MORATORIO,xmoratorio@msp.gub.uy\n\n\n\n\n\n\n\nTenemos la tabla! Aunque, realmente no es lo que esperábamos. Para empezar, los nombres de las columnas no son correctos. Parece ser que read.table por defecto no se da cuenta que la primera fila corresponde a los encabezados de la tabla. Vamos a tener que aclarárselo también.\n\ndata <- read.table(\n  file = \"../data/courseid_3282_participants.csv\", \n  fill = NA,\n  header = TRUE\n)\n\n\n\n\n\n\nNombre.Apellido.s…Dirección\nde\ncorreo.\n\n\n\n\nCECILIA,CARPENA,mcarpena@msp.gub.uy\nNA\nNA\n\n\nMarines,FIGUEROA,mfigueroa@msp.gub.uy\nNA\nNA\n\n\nLUCA,AICARDI,maicardi@msp.gub.uy\nNA\nNA\n\n\nMARCELA,CASTRO,mfcastro@msp.gub.uy\nNA\nNA\n\n\nMARIA,MORATORIO,xmoratorio@msp.gub.uy\nNA\nNA\n\n\nDaniel,BLANC,dblanc@ine.gub.uy\nNA\nNA\n\n\n\n\n\nCorregimos los encabezados! Pero aún parece que hay problemas: notoriamente esta tabla debería tener tres columnas: nombre, apellido y dirección de correo. Pero esto no ocurre.\nEl problema radica en que read.table toma por defecto que el separador de los datos es un espacio en blanco. Es por esto que dirección de correo está separado como si fueran tres columnas. Debemos especificarle cuál es el separador correcto: la coma.\n\ndata <- read.table(\n  file = \"../data/courseid_3282_participants.csv\", \n  fill = NA,\n  header = TRUE,\n  sep = \",\"\n)\n\n\n\n\n\n\nNombre\nApellido.s.\nDirección.de.correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy\n\n\n\n\n\nYa casi es nuestra tabla! Pero siguen habiendo cuestiones a pulir, y es que parece haber algún problema con los caracteres especiales, tales como los paréntesis o tildes. Podemos solucionar esto especificando el tipo de encoding que tiene el archivo. Para descubrir el mismo, debemos mirar en la parte inferior derecha del archivo de texto plano.\n\n\ndata <- read.table(\n  file = \"../data/courseid_3282_participants.csv\", \n  fill = NA,\n  header = TRUE,\n  sep = \",\",\n  fileEncoding = 'UTF-8-BOM'\n)\n\n\n\n\n\n\nNombre\nApellido.s.\nDirección.de.correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy\n\n\n\n\n\nAhora si tenemos nuestra tabla! R no es amigo de los caracteres especiales de ningún tipo. Está pensado para nombres funcionales e informáticos, no para humanos. Por tanto, conviene darles los nombres que nosotros queremos a los encabezados.\n\ndata <- read.table(\n  file = \"../data/courseid_3282_participants.csv\", \n  fill = NA,\n  header = TRUE,\n  sep = \",\",\n  fileEncoding = 'UTF-8-BOM',\n  col.names = c('nombre', 'apellido', 'direccion_correo')\n)\n\n\n\n\n\n\nnombre\napellido\ndireccion_correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy\n\n\n\n\n\nComo se ha visto, para importar una tabla de texto plano en R se deben tomar en cuenta los siguientes elementos:\n\nSi el archivo tiene encabezados\nCuál es el separador de los datos\nSi hay que rellenar espacios en blancos con NA\nEl encoding del archivo\n\nLo cierto es que read.table es la versión más básica de una serie de funciones que sirven para el mismo propósito. Si ya conocemos de antemano el formato en que viene nuestro dataset, podemos usar funciones que requieran menos trabajo para obtener la información.\nPor ejemplo, si sabemos que nuestro archivo es un csv, podemos usar la función read.csv. Esta función ya da por hecho que el dataset contiene los encabezados en la primera fila y que el separador es una coma. Para alcanzar el mismo resultado que antes, solo debemos aclararle el encoding y el nombre que queremos para las columnas.\n\ndata <- read.csv(\n  file = \"../data/courseid_3282_participants.csv\",\n  fileEncoding = 'UTF-8-BOM',\n  col.names = c('nombre', 'apellido', 'direccion_correo')\n)\n\n\n\n\n\n\nnombre\napellido\ndireccion_correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy\n\n\n\n\n\n\nTomar en cuenta que tanto read.csv, read.csv2, read.delim, entre muchas otras funciones, son de la misma “familia” que read.table. Funcionan prácticamente igual solo que cambian los parámetros por defecto.\n\nLo devuelto por estas funciones, es un data frame, lo cual es un objeto computacional diseñado para almacenar datos con forma de tabla.\n\n\n\nAdicionalmente, el paquete data.table, tiene una función llamada fread que permite no solo ser más eficiente con la lectura de los datos, sino que no requiere especificación de separador.\n\nlibrary(data.table)\ndata <- fread(\"../data/courseid_3282_participants.csv\")\n\n\n\n\n\n\nNombre\nApellido(s)\nDirección de correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy\n\n\n\n\n\nEl único inconveniente parece ser el encoding, pero aclarándoselo, la función nos trae la información perfectamente.\n\ndata <- fread(\n  file = \"../data/courseid_3282_participants.csv\",\n  encoding = \"UTF-8\"\n)\n\n\n\n\n\n\nNombre\nApellido(s)\nDirección de correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy\n\n\n\n\n\n\n\n\nHay un paquete en R especializado en la lectura de archivos. Ese paquete se llama readr. El objetivo de este paquete es realizar una importación de datos más veloz y eficiente. Además, nos ahorra tiempo en la medida que detecta automáticamente el separador de los datos.\n\nlibrary(readr)\ndata <- read_csv(\"../data/courseid_3282_participants.csv\")\n\nRows: 15 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Nombre, Apellido(s), Dirección de correo\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\nNombre\nApellido(s)\nDirección de correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy\n\n\n\n\n\nEsta función no solo lee la información con mayor velocidad, sino que también es más inteligente a la hora de resolver la cuestión del encoding y el problema de los nombres de las columnas. También nos brinda información sobre el dataset, como la cantidad de filas, columnas, y el tipo de dato de ellas. Podemos acceder a mayor información sobre esto último su complementamos con la función spec.\n\nspec(data)\n\ncols(\n  Nombre = col_character(),\n  `Apellido(s)` = col_character(),\n  `Dirección de correo` = col_character()\n)\n\n\nEl paquete readr permite también editar el tipo de las columnas en el momento que se realiza la importación. De este modo, si tenemos que hacer un cambio de tipo de dato, podemos hacerlo integrado a la función, sin tener que dedicar tiempo a eso después.\n\ndata <- read_csv(\n  file = \"../data/courseid_3282_participants.csv\",\n  col_names = c(\"nombre\", \"apellido\", \"direccion_correo\"),\n  col_types = cols(\n    nombre = col_character(),\n    apellido = col_character(),\n    direccion_correo = col_character()\n  )\n)\n\n\n\n\n\n\nnombre\napellido\ndireccion_correo\n\n\n\n\nNombre\nApellido(s)\nDirección de correo\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\n\n\n\n\nComo notarán, antes de asignarle un tipo de dato a las columnas, les asigné el nombre, de modo que R supiera a cuál me estaba refieriendo en cada caso. A veces cuando los encabezados tienen espacios o tildes, o cuestiones de ese estilo, y no son solo letras y guiones, R puede asignarles nombres inesperados.\n\nSin embargo, esto nos trajo un problema, ya que parece que readr entiende que si le ponemos nombres a las columnas, es que en realidad no tienen nombres, y la primera fila son datos y no encabezados. Por tanto, para solucionar esto debemos pedirle que omita la primera fila. Para ello, se usa el parámetro skip.\n\ndata <- read_csv(\n  file = \"../data/courseid_3282_participants.csv\",\n  col_names = c(\"nombre\", \"apellido\", \"direccion_correo\"),\n  col_types = cols(\n    nombre = col_character(),\n    apellido = col_character(),\n    direccion_correo = col_character()\n  ),\n  skip = 1\n)\n\n\n\n\n\n\nnombre\napellido\ndireccion_correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy"
  },
  {
    "objectID": "chapters/import.html#archivos-de-excel",
    "href": "chapters/import.html#archivos-de-excel",
    "title": "2  Importación de datos",
    "section": "2.2 Archivos de excel",
    "text": "2.2 Archivos de excel\nExcel es otro clásico modo de almacenar información, aunque no en grandes volúmenes. Para poder leer información de esta fuente, se puede recurrir al paquete openxlsx.\n\nlibrary(openxlsx)\ndata <- read.xlsx(\"../data/ACV EFMA 2022.xlsx\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodigo\nInstitucion\nSexo\nFecha.de.nacimiento\nFecha.ACV\nTrombolisis.medicamentosa\n\n\n\n\n138\nAMDM\nM\n15014\n44565\nNO\n\n\n138\nAMDM\nM\n21693\n44565\nNO\n\n\n138\nAMDM\nM\n16604\n44566\nNO\n\n\n138\nAMDM\nM\n21545\n44567\nNO\n\n\n138\nAMDM\nF\n19542\n44568\nNO\n\n\n138\nAMDM\nF\n17541\n44570\nNO\n\n\n\n\n\n\nObtener datos desde excel por lo general requiere poco trabajo, ya que la información está delimitada en las propias celdas de excel y no tenemos que aclararle mucho a la función. Lo único que nos puede dar problema es la cuestión del formato de las fechas, ya que excel almacena las fechas como números enteros.\n\nPara evitar que esto suceda, debemos utilizar el parámetro correspondiente: detectDates.\n\ndata <- read.xlsx(\n  xlsxFile = \"../data/ACV EFMA 2022.xlsx\",\n  detectDates = TRUE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodigo\nInstitucion\nSexo\nFecha.de.nacimiento\nFecha.ACV\nTrombolisis.medicamentosa\n\n\n\n\n138\nAMDM\nM\n1941-02-07\n2022-01-04\nNO\n\n\n138\nAMDM\nM\n1959-05-23\n2022-01-04\nNO\n\n\n138\nAMDM\nM\n1945-06-16\n2022-01-05\nNO\n\n\n138\nAMDM\nM\n1958-12-26\n2022-01-06\nNO\n\n\n138\nAMDM\nF\n1953-07-02\n2022-01-07\nNO\n\n\n138\nAMDM\nF\n1948-01-09\n2022-01-09\nNO\n\n\n\n\n\nTambién se puede seleccionar de qué hoja del libro hacer la lectura, entre otras cuestiones. Para seleccionar la hoja, se puede poner tanto el nombre de la hoja, como el número.\n\ndata <- read.xlsx(\n  xlsxFile = \"../data/ACV EFMA 2022.xlsx\",\n  detectDates = TRUE,\n  sheet = 2\n)\n\n\n\n\n\n\nNombre\nApellido(s)\nDirección.de.correo\n\n\n\n\nCECILIA\nCARPENA\nmcarpena@msp.gub.uy\n\n\nMarines\nFIGUEROA\nmfigueroa@msp.gub.uy\n\n\nLUCA\nAICARDI\nmaicardi@msp.gub.uy\n\n\nMARCELA\nCASTRO\nmfcastro@msp.gub.uy\n\n\nMARIA\nMORATORIO\nxmoratorio@msp.gub.uy\n\n\nDaniel\nBLANC\ndblanc@ine.gub.uy"
  },
  {
    "objectID": "chapters/import.html#archivos-de-spss",
    "href": "chapters/import.html#archivos-de-spss",
    "title": "2  Importación de datos",
    "section": "2.3 Archivos de SPSS",
    "text": "2.3 Archivos de SPSS\nEs muy común migrar de SPSS a R, y por tanto, hay un paquete que tenemos que tener presente para acceder a archivos creados a partir de esa herramienta, y es el haven. Dentro de ese paquete, tenemos una función denominada read_sav, que sirve para acceder a acceder a archivos de este estilo.\n\nlibrary(haven)\ndata <- read_sav(\"../data/Natalidad2021_ENAP_CursoR.sav\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nedadm\npaism\ndepar\ncodep\nnumemban\nsemprim\ntotcons\natendio\ncesopar\ntipoces\nesmult\nmultiplicidad\nsexo\npeso\nsemgest\npartlug\nmestciv\nestab\n\n\n\n\n35\n1\n18\n10\n0\n8\n11\n1\n2\n1\n2\n3\n2\n800\n32\n1\n2\n103\n\n\n35\n1\n18\n10\n0\n8\n11\n1\n2\n1\n2\n3\n2\n800\n32\n1\n2\n103\n\n\n35\n1\n18\n10\n0\n8\n11\n1\n2\n1\n2\n3\n2\n1580\n32\n1\n2\n103\n\n\n35\n2\n10\n10\n0\n7\n10\n1\n2\n1\n2\n3\n1\n2080\n34\n1\n1\n78\n\n\n35\n2\n10\n10\n0\n7\n10\n1\n2\n1\n2\n3\n1\n2430\n34\n1\n1\n78\n\n\n35\n2\n10\n10\n0\n7\n10\n1\n2\n1\n2\n3\n2\n1920\n34\n1\n1\n78"
  },
  {
    "objectID": "chapters/import.html#otros-métodos",
    "href": "chapters/import.html#otros-métodos",
    "title": "2  Importación de datos",
    "section": "2.4 Otros métodos",
    "text": "2.4 Otros métodos\nAdemás de usar estas funciones, es posible importar la información desde comandos del RStudio. Lo que esto permite es generar el código de la función sin tener que escribirlo. Se puede hacer seleccionando el botón import en la parte superior de la pestaña de Environment.\n\nSi queremos subir datos de forma rápida en R, podemos usar la función read.clipboard, que convierte en dataframe lo que tengamos seleccionado."
  },
  {
    "objectID": "chapters/import.html#exportación-de-archivos",
    "href": "chapters/import.html#exportación-de-archivos",
    "title": "2  Importación de datos",
    "section": "2.5 Exportación de archivos",
    "text": "2.5 Exportación de archivos\nAdemás de importar archivos a R, podemos exportarlos, y para eso usamos las funciones write, en lugar de las read. Para esto, suele ser suficiente utilizar las funciones básicas de R, ya que por lo general esto no requiere mucha sofisticación.\nAl igual que como sucede con la importación, en la exportación debemos considerar además del nombre del archivo, los mismos elementos que al importar: con qué elemento se van a separar los valores, el encoding del archivo, etc.\n\nNo debemos olvidar colocar la terminación al final del nombre del archivo.\n\n\nwrite.csv(\n  x = data,\n  file = \"data_exportada.csv\",\n  row.names = FALSE,\n  fileEncoding = 'UTF-8'\n)\n\n\nwrite.xlsx(\n  x = data,\n  file = \"data_exportada.xlsx\"\n)"
  },
  {
    "objectID": "chapters/dataframes.html",
    "href": "chapters/dataframes.html",
    "title": "3  Estructura de data frames",
    "section": "",
    "text": "En el laboratorio anterior se vio cómo obtener los datos proveenientes de distintos tipos de archivos. En esa tarea uno conoce el formato y estructura básica de un dataset, mas a partir de ahora es necesario concentrarse en los componentes estadísticos del mismo.\n\n\nCuando almacenamos una tabla, se convierte en un data frame, que es un objeto de R pensado para almacenar información estructurada como una tabla. Podemos encontrar el tipo de objeto de cualquier elemento en R utilizando la función class.\nEsto ocurre también para los vectores, los cuales adquieren un tipo de dato. Los tipos de dato más habituales son los caracteres, las números y los factores. Los factores son un método de guardado de R que sirve para incorporar valores categóricos que se repiten mucho, por ejemplo el sexo, mientras que no es tan útil para los nombres.\n\nnombres <- c('Daniel', 'Nicolás', 'Andrea')\nclass(nombres)\n\n[1] \"character\"\n\n\n\nedades <- c(30,42,28)\nclass(edades)\n\n[1] \"numeric\"\n\n\nEstos tipos de datos son los que tendrán las columnas de nuestros dataframes. Los dataframes están compuestos por una serie de vectores de similar longitud.\n\ndf <- data.frame(nombres, edades)\ndf\n\n  nombres edades\n1  Daniel     30\n2 Nicolás     42\n3  Andrea     28\n\n\nUn dataframe se muestra con un número de fila incremental a la izquierda, mientras que toma el nombre de los vectores como encabezados para las columnas, y los valores de los mismos como el contenido.\n\nclass(df)\n\n[1] \"data.frame\"\n\n\n\n\n\nAl considerar un dataframe, debe verse como un elemento de dos entradas: filas y columnas. Si el objetivo es acceder a un determinado valor, se deben dar instrucciones de cómo llegar al dato. Por ejemplo, si se quiere acceder a la edad de Nicolás, debemos indicarle en qué fila y columna se encuentra.\n\ndf[2,2]\n\n[1] 42\n\n\nPara especificar esta cuestión, es necesario abrir paréntesis rectos luego del nombre de la tabla, y específicar el número de fila previo a la coma, y el número de columna posterior a la coma.\nSi quisiéramos obtener más información, podemos incorporar varias filas o columnas, ya sea seleccionándolas manualmente o si están de corrido, utilizar un slicing.\n\ndf[2,c(1,2)]\n\n  nombres edades\n2 Nicolás     42\n\n\n\ndf[2,1:2]\n\n  nombres edades\n2 Nicolás     42\n\n\nCuando se trae más información, se despliegan los nombres de las columnas y el número de fila. Estos métodos se pueden utilizar para filtrar un dataset, mas no es el método más conveniente en general.\n\ndf2 <- df[1:2,1:2]\ndf2\n\n  nombres edades\n1  Daniel     30\n2 Nicolás     42\n\n\nResulta más conveniente brindar una condición por la cual filtrar el dataset, ya que esto no varía luego según la cantidad de filas u otros cambios. Se verá este tipo de cuestión con un dataset de ejemplo."
  },
  {
    "objectID": "chapters/dataframes.html#explorando-un-dataset",
    "href": "chapters/dataframes.html#explorando-un-dataset",
    "title": "3  Estructura de data frames",
    "section": "3.2 Explorando un dataset",
    "text": "3.2 Explorando un dataset\nLo primero que debemos hacer es obtener un dataset. Siempre es conveniente ver las primeras filas de la tabla para ver en qué formato llegaron. Esto puede hacerse con la función head.\n\nlibrary(openxlsx)\ndata <- read.xlsx(\n  xlsxFile = \"../data/Chapter_3/data_c_1.xlsx\",\n  detectDates = TRUE\n)\nhead(data)\n\n                                             empresa_farmaceutica sexo\n1                                            Bedford Laboratories    F\n2                                                   LUPIN LIMITED    M\n3 E. Fougera &amp; Co. a division of Fougera Pharmaceuticals Inc.    M\n4                                             Prasco Laboratories    M\n5                           State of Florida DOH Central Pharmacy    F\n6                                          Sagent Pharmaceuticals    F\n  fecha.de.nacimiento consume.medicamento fecha.de.enfermedad\n1          21/12/2003                   1          31/12/2021\n2          07/07/2004                   0          15/08/2022\n3          14/03/2003                   1          06/07/2022\n4          13/10/2003                   1          10/06/2022\n5          23/06/2005                   0          15/04/2022\n6          10/03/2003                   1          13/12/2021\n\n\nLa función clásica para comprender el estructura de un dataset, es justamente str. Esto nos permite ver el tipo de dato de cada variable, junto con la cantidad de variables y observaciones.\n\nstr(data)\n\n'data.frame':   854 obs. of  5 variables:\n $ empresa_farmaceutica: chr  \"Bedford Laboratories\" \"LUPIN LIMITED\" \"E. Fougera &amp; Co. a division of Fougera Pharmaceuticals Inc.\" \"Prasco Laboratories\" ...\n $ sexo                : chr  \"F\" \"M\" \"M\" \"M\" ...\n $ fecha.de.nacimiento : chr  \"21/12/2003\" \"07/07/2004\" \"14/03/2003\" \"13/10/2003\" ...\n $ consume.medicamento : num  1 0 1 1 0 1 0 1 1 0 ...\n $ fecha.de.enfermedad : chr  \"31/12/2021\" \"15/08/2022\" \"06/07/2022\" \"10/06/2022\" ...\n\n\nEste dataset tiene una sola variable numérica, junto a tres variables de texto y dos de fecha. Si tuvieramos más variables numéricas podríamos usar la función summary, que sirve para brindar una serie de elementos estadísticos sobre las variables. Usaremos un dataset nativo de R llamado Iris para poder aplicarlo.\n\niris <- iris\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nComo puede apreciarse, el summary trae información estadística de las variables numéricas, e ignora a las de otro tipo de dato. Este tipo de funciones son muy útiles para comprobar que el dataset se importó correctamente y que las variables tienen el valor deseado. Por lo general una cuestión que esto revela es si el indicador de decimal es el correcto, por definición R considera el “.” como separador decimal, pero en el idioma español se utiliza por lo general la “,”.\nVolviendo a nuestro dataset, en caso de querer conocer, por ejemplo, la frecuencia de valores de una variable categórica, se puede usar la función table. Para indicarle a R que queremos acceder a una columna del dataframe, debemos utilizar el $ antes del nombre de la columna.\n\ntable(data$sexo)\n\n\n  F   M \n441 413 \n\n\nTambién se puede acceder a la cantidad relativa.\n\nprop.table(table(data$sexo))\n\n\n        F         M \n0.5163934 0.4836066 \n\n\nSe puede hacer esto combinando las variables\n\ntable(data$sexo, data$consume.medicamento)\n\n   \n      0   1\n  F 222 219\n  M 209 204\n\n\n\nprop.table(\n  table(\n    data$sexo,\n    data$consume.medicamento\n  ),\n  margin = 2\n)\n\n   \n            0         1\n  F 0.5150812 0.5177305\n  M 0.4849188 0.4822695\n\n\n\nprop.table(\n  table(\n    data$sexo,\n    data$consume.medicamento\n  ),\n  margin = 1\n)\n\n   \n            0         1\n  F 0.5034014 0.4965986\n  M 0.5060533 0.4939467\n\n\n\nModificación de tipos de datos\nLas columnas de los dataset tienen tipos de datos asignados, pero estos pueden ser modificables, siempre y cuando sea coherente. Por ejemplo, podemos almacenar un “2” como un texto, pero no almacenar un “hola” como un número. Para transformar los tipos de datos podemos utilizar varios métodos, uno como ya vimos es hacerlo durante la importación, otro es usando las funciones as.type\n\ndata$sexo <- as.factor(data$sexo)\ndata$empresa_farmaceutica <- as.factor(data$empresa_farmaceutica)\n\n¿Se acuerdan de summary? Con los factores funciona también.\n\nsummary(data)\n\n                  empresa_farmaceutica sexo    fecha.de.nacimiento\n REMEDYREPACK INC.          : 25       F:441   Length:854         \n Cardinal Health            : 19       M:413   Class :character   \n Nelco Laboratories, Inc.   : 19               Mode  :character   \n Physicians Total Care, Inc.: 19                                  \n Antigen Laboratories, Inc. : 11                                  \n Bryant Ranch Prepack       : 11                                  \n (Other)                    :750                                  \n consume.medicamento fecha.de.enfermedad\n Min.   :0.0000      Length:854         \n 1st Qu.:0.0000      Class :character   \n Median :0.0000      Mode  :character   \n Mean   :0.4953                         \n 3rd Qu.:1.0000                         \n Max.   :1.0000"
  },
  {
    "objectID": "chapters/data_analisis.html",
    "href": "chapters/data_analisis.html",
    "title": "4  Análisis de datos",
    "section": "",
    "text": "El paquete por excelencia para realizar análisis de datos con R se denomina tidyverse. Este paquete no es un paquete en si mismo, sino una colección de múltiples paquetes que comparten el objetivo: realizar análisis de datos.\nAl ser muchos paquetes, tarda un poco en instalar.\n\ninstall.packages('tidyverse')\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "chapters/data_manipulation.html",
    "href": "chapters/data_manipulation.html",
    "title": "5  Manipulación de datos",
    "section": "",
    "text": "En muchas ocasiones debemos trabajar con varias tablas de forma simultánea, y en otras debemos unificarlas para llegar a la tabla final con la que haremos el análisis. Para hacer estas uniones, debemos ya sea combinar las tablas, o anexarlas.\n\n\nAnexar dos tablas implica “poner una encima de la otra”, es decir, que las filas de una de las tablas se unan a la otra. Para alcanzar esto debemos tener dos dataframes con estructura similar, es decir que tengan la misma cantidad de variables y que éstas tengan encabezados similares.\nPara ejemplificar estos casos vamos a trabajar con una serie de tablas ficticias, que responden a los datos de un restaurant imaginario. Lo primero que importaremos son las tablas de ventas de la semana uno y la semana dos.\n\nsemana_1 <- read.csv(\"../data/Chapter_5/Restaurant - Week 1 Sales.csv\")\nhead(semana_1)\n\n  Customer.ID Food.ID\n1         537       9\n2          97       4\n3         658       1\n4         202       2\n5         155       9\n6         213       8\n\n\n\nsemana_2 <- read.csv(\"../data/Chapter_5/Restaurant - Week 2 Sales.csv\")\nhead(semana_2)\n\n  Customer.ID Food.ID\n1         688      10\n2         813       7\n3         495      10\n4         189       5\n5         267       3\n6         310       5\n\n\nTal como puede apreciarse, ambos dataframes tienen dos columnas que corresponden una al id de la comida y otra al id del cliente. Dado que estos dataframes comparten la misma estructura, es posible unirlos. Para hacerlo podemos usar la función rbind.\n\nventas <- rbind(semana_1, semana_2)\nhead(ventas)\n\n  Customer.ID Food.ID\n1         537       9\n2          97       4\n3         658       1\n4         202       2\n5         155       9\n6         213       8\n\n\nDe esta forma, obtenemos un dataframe de 500 filas y la misma cantidad de columnas.\n\n\n\nOtra clásica necesidad que se presenta a la hora de trabajar con muchas tablas es el tener que combinarlas. Las combinaciones suceden mediante reglas de unión: a través de una determinada clave, cuando estas coinciden entre dos tablas, se pegan las columnas. Los tipos de unión son los siguientes:\n\n\n\n\n\n\nINNER JOIN: solo quedan las filas que tengan la clave en ambos dataset.\nFULL JOIN: quedan todas las filas, sin importar si matchean o no\nLEFT JOIN: las filas de la tabla de la izquierda quedan todas, se agregan las que coincidan de la derecha.\nRIGHT JOIN: las filas de la tabla de la derecha quedan todas, se agregan las que coincidan de la izquierda.\n\nTidyverse tiene funciones específicas para realizar estas uniones. Comencemos importando las tablas a combinar. La tabla de comidas tiene información sobre el id de cada comida del menú, junto con el nombre del item y su precio.\n\ncomida <- read.csv(\"../data/Chapter_5/Restaurant - Foods.csv\")\nhead(comida)\n\n  Food.ID  Food.Item Price\n1       1      Sushi  3.99\n2       2    Burrito  9.99\n3       3       Taco  2.99\n4       4 Quesadilla  4.25\n5       5      Pizza  2.49\n6       6      Pasta 13.99\n\n\nEl objetivo será combinar esta tabla con la de ventas para tener la descripción y el precio de cada item en la tabla principal. La variable que unirá ambas tablas será Food.ID\n\nlibrary(tidyverse)\nunion <- ventas %>% inner_join(comida, by = \"Food.ID\")\nhead(union)\n\n  Customer.ID Food.ID  Food.Item Price\n1         537       9      Donut  0.99\n2          97       4 Quesadilla  4.25\n3         658       1      Sushi  3.99\n4         202       2    Burrito  9.99\n5         155       9      Donut  0.99\n6         213       8      Salad 11.25\n\n\nPara cada Food.ID, la unión trajo el resto de las columnas de la tabla de comida que coincidiera. Para el caso de los clientes tenemos un problema, y es que la columna por la cual se hará la unión no es similar en ambas tablas. Mientras que en ventas la variable se llama Costumer.ID, en clientes se llama ID. Por tanto, tengo que adaptar mi función de combinación, aclarando cómo se llama cada variable en cada tabla.\n\nclientes <- read.csv(\"../data/Chapter_5/Restaurant - Customers.csv\")\nhead(clientes)\n\n  ID First.Name Last.Name Gender       Company                    Occupation\n1  1     Joseph   Perkins   Male       Dynazzy Community Outreach Specialist\n2  2   Jennifer   Alvarez Female          DabZ       Senior Quality Engineer\n3  3      Roger     Black   Male       Tagfeed             Account Executive\n4  4     Steven     Evans   Male          Fatz              Registered Nurse\n5  5       Judy  Morrison Female       Demivee               Legal Assistant\n6  6     Amanda    Howell Female Thoughtbridge              Dental Hygienist\n\n\nUna opción es modificar el nombre de la columna en una de las dos tablas. De otra forma, puede hacerse así:\n\nunion <- union %>% inner_join(clientes, by = c(\"Customer.ID\" = \"ID\"))\nhead(union)\n\n  Customer.ID Food.ID  Food.Item Price First.Name Last.Name Gender   Company\n1         537       9      Donut  0.99     Cheryl   Carroll Female  Zoombeat\n2          97       4 Quesadilla  4.25     Amanda   Watkins Female       Ozu\n3         658       1      Sushi  3.99    Patrick      Webb   Male Browsebug\n4         202       2    Burrito  9.99      Louis  Campbell   Male Rhynoodle\n5         155       9      Donut  0.99    Carolyn      Diaz Female  Gigazoom\n6         213       8      Salad 11.25      Keith    Foster   Male Gigashots\n                     Occupation\n1              Registered Nurse\n2           Account Coordinator\n3 Community Outreach Specialist\n4    Account Representative III\n5    Database Administrator III\n6            VP Quality Control\n\n\nDe esta forma, obtenemos la tabla final, en donde pueden realizar análisis.\n\n\n\n\nObtenga las cinco comidas que más se consumen.\nIndique qué cliente ha gastado más en el restaurant.\n¿Cuánto ha sido el gasto promedio por sexo?\n\n\n\nPosible solución\ncinco_comidas <- union %>% \n  group_by(Food.Item) %>% \n  summarise(cantidad = n()) %>% \n  arrange(desc(cantidad)) %>% \n  head(5)\n\ncliente_mas_gastador <- union %>% \n  group_by(Customer.ID, First.Name, Last.Name) %>% \n  summarise(gasto = sum(Price)) %>% \n  arrange(desc(gasto)) %>% \n  head(1)\n\ngasto_por_sexo <- union %>% \n  group_by(Gender) %>% \n  summarise(gasto_promedio = mean(Price))"
  },
  {
    "objectID": "chapters/data_manipulation.html#manejo-de-nas",
    "href": "chapters/data_manipulation.html#manejo-de-nas",
    "title": "5  Manipulación de datos",
    "section": "5.2 Manejo de NAs",
    "text": "5.2 Manejo de NAs\n\nIdentificación de datos faltantes\nLos datos faltantes son una realidad cotidiana dentro del análisis de datos. Toda estructura de información está sujeta a fallas y esto es complementado por la posible carencia de datos provenientes del provedor.\nEstos missing pueden aparecer de varias formas: celdas vacías, textos vacíos, o elementos que identifiquen que un dato es faltante, por ejemplo, un texto que diga “sin dato”.\n\ndatos <- read.csv(\"../data/Chapter_5/data_c_1.csv\", encoding = \"UTF-8\")\nhead(datos)\n\n  id      date                      product revenue         city product_type\n1  1 26/3/2020     Lettuce - Belgian Endive    3139        Laxey      premiun\n2  2 27/5/2020     Table Cloth 91x91 Colour    4726 Svyetlahorsk      regular\n3  3 24/6/2020                   Pur Source    3117      Cabuyao             \n4  4 10/7/2020 Syrup - Monin - Blue Curacao    2575   Nouakchott      regular\n5  5 22/7/2020               Steamers White    3136       Timrat         gold\n6  6 11/3/2020       Wine - Delicato Merlot    1939    Glinojeck         gold\n\n\nAl abrir este dataset, puede observarse con claridad que hay algunos campos que tienen valores faltantes, sin embargo, R no los identifica. Para R hay un valor faltante cuando aparece el elemento NA. Si éste no aparece, el contenido del dato tiene un valor. El problema en este caso es que los campos vacíos R no logra identificarlos como NA, hay que indicárselo.\n\ndatos <- read.csv(\n  file = \"../data/Chapter_5/data_c_1.csv\", \n  stringsAsFactors = TRUE, \n  encoding = \"UTF-8\", \n  na.strings = c(\"\", \"NA\")\n)\nhead(datos)\n\n  id      date                      product revenue         city product_type\n1  1 26/3/2020     Lettuce - Belgian Endive    3139        Laxey      premiun\n2  2 27/5/2020     Table Cloth 91x91 Colour    4726 Svyetlahorsk      regular\n3  3 24/6/2020                   Pur Source    3117      Cabuyao         <NA>\n4  4 10/7/2020 Syrup - Monin - Blue Curacao    2575   Nouakchott      regular\n5  5 22/7/2020               Steamers White    3136       Timrat         gold\n6  6 11/3/2020       Wine - Delicato Merlot    1939    Glinojeck         gold\n\n\nComo puede apreciarse, se agrega un parámetro denominado na.strings como forma de indicarle a R cuando un valor de caracter debe tomarse como NA. Además, se ha agregado un parámetro que le pide a R que los valores de texto los almacene como factores. Esto lo hacemos especialmente en este caso, para realizar un conteo de NAs mediante la función summary.\n\nsummary(datos)\n\n       id                date                          product   \n Min.   :   1.0   4/11/2020:  9   Danishes - Mini Raspberry:  5  \n 1st Qu.: 250.8   13/1/2021:  8   Cake - Bande Of Fruit    :  4  \n Median : 500.5   15/2/2020:  8   Beef - Tongue, Cooked    :  3  \n Mean   : 500.5   19/7/2020:  7   Beer - Upper Canada Lager:  3  \n 3rd Qu.: 750.2   29/5/2020:  7   Bouillion - Fish         :  3  \n Max.   :1000.0   (Other)  :942   (Other)                  :933  \n                  NA's     : 19   NA's                     : 49  \n    revenue             city      product_type\n Min.   :1001   Guadalupe :  3   gold   :302  \n 1st Qu.:2049   København :  3   premiun:325  \n Median :3073   Buenavista:  2   regular:321  \n Mean   :3058   Cabrobó   :  2   NA's   : 52  \n 3rd Qu.:4108   Córdoba   :  2                \n Max.   :4999   (Other)   :965                \n NA's   :23     NA's      : 23                \n\n\nDe esta forma, el summary toma los NA como otro valor dentro de las variables, y realiza un conteo. Otra forma de obtener esta información es mediante la función skim. Esta función está pensada para realizar una serie de averiguaciones en una tabla y devolver un diagnóstico de los datos muy completo. Para usarla hay que llamar al paquete skimr\n\nlibrary(skimr)\nskim(datos)\n\n\nData summary\n\n\nName\ndatos\n\n\nNumber of rows\n1000\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ndate\n19\n0.98\nFALSE\n341\n4/1: 9, 13/: 8, 15/: 8, 19/: 7\n\n\nproduct\n49\n0.95\nFALSE\n786\nDan: 5, Cak: 4, Bee: 3, Bee: 3\n\n\ncity\n23\n0.98\nFALSE\n954\nGua: 3, Køb: 3, Bue: 2, Cab: 2\n\n\nproduct_type\n52\n0.95\nFALSE\n3\npre: 325, reg: 321, gol: 302\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1.00\n500.50\n288.82\n1\n250.75\n500.5\n750.25\n1000\n▇▇▇▇▇\n\n\nrevenue\n23\n0.98\n3058.06\n1185.29\n1001\n2049.00\n3073.0\n4108.00\n4999\n▇▆▆▇▇\n\n\n\n\n\n\n\nManejo de datos faltantes\nLuego de identificar los valores faltantes de nuestro dataframe, la decisión siguiente a tomar es qué hacer con ellos.\nHay varias posibilidades:\n\nEliminar los valores faltantes\nReemplazar las variables numéricas con:\n\nLa media, mediana, o algún valor estadístico\nPor ceros\n\nReemplazar las variables categóricas con:\n\nEl valor más frecuente\nOtro valor (por ejemplo: “Otro”)\n\n\n\nEliminar valores faltantes\nSi decidimos eliminar los valores faltantes, podemos usar la función drop_na, del paquete tidyverse, que elimina la fila entera en donde encuentra un NA.\n\nlibrary(tidyverse)\ndatos %>% drop_na() %>% head()\n\n  id      date                      product revenue         city product_type\n1  1 26/3/2020     Lettuce - Belgian Endive    3139        Laxey      premiun\n2  2 27/5/2020     Table Cloth 91x91 Colour    4726 Svyetlahorsk      regular\n3  4 10/7/2020 Syrup - Monin - Blue Curacao    2575   Nouakchott      regular\n4  5 22/7/2020               Steamers White    3136       Timrat         gold\n5  6 11/3/2020       Wine - Delicato Merlot    1939    Glinojeck         gold\n6  7  1/6/2020  Island Oasis - Magarita Mix    2283  Châteauroux         gold\n\n\nEsta función resulta bastante flexible y permite varios tratamientos de NA. Por ejemplo, si quisiéramos eliminar NA de alguinas columnas en particular, podemos aclarárselo.\n\ndatos %>% drop_na(any_of(c(\"date\", \"product\"))) %>% head()\n\n  id      date                      product revenue         city product_type\n1  1 26/3/2020     Lettuce - Belgian Endive    3139        Laxey      premiun\n2  2 27/5/2020     Table Cloth 91x91 Colour    4726 Svyetlahorsk      regular\n3  3 24/6/2020                   Pur Source    3117      Cabuyao         <NA>\n4  4 10/7/2020 Syrup - Monin - Blue Curacao    2575   Nouakchott      regular\n5  5 22/7/2020               Steamers White    3136       Timrat         gold\n6  6 11/3/2020       Wine - Delicato Merlot    1939    Glinojeck         gold\n\n\n\n\nReemplazar variables numéricas y categóricas\nOtras veces necesitamos no eliminar, sino reemplazar los valores faltantes por un valor que resulte conveniente.\n\nLa decisión sobre este procedimiento debe ser acorde al contenido conceptual del dataset y no hay una solución única para todas las ocasiones.\n\nSi queremos generar un reemplazo de NAs por un valor calculado, digamos, la media de esa variable, podemos guardar dicho valor en un objeto y luego imputarlo con la función replace_na. Dicha función debe recibir una lista que indique qué imputar a cada variable. Si queremos hacerlo con una sola, se especifica la variable, sino, se van agregando con comas.\nPara ver el impacto de esta técnica, localizaremos un NA en la fila 31 en la variable revenue y veremos cómo se modifica. Para visualizarlo, podemos ver la tabla entera con la función View o vamos directo a esa sección con la función slice.\n\ndatos %>% slice(25:35)\n\n   id      date                            product revenue            city\n1  25 11/8/2020                               <NA>    1723         Gaocang\n2  26 5/10/2020           Chocolate Bar - Smarties    1969           Rizal\n3  27  6/9/2020                  Tea - Decaf 1 Cup    4202        Mrganush\n4  28  9/3/2020           Bread - Multigrain, Loaf    1190 Aveiras de Cima\n5  29 27/5/2020                Lamb Rack - Ontario    4605          Paihia\n6  30 14/3/2020        Chocolate - Mi - Amere Semi    3540          Lañgub\n7  31 18/8/2020              Cheese - Gouda Smoked      NA            <NA>\n8  32  2/5/2020               Apple - Granny Smith    4848      Cineumbeuy\n9  33 14/5/2020 Chocolate - Liqueur Cups With Foil    1607         Borjomi\n10 34 17/3/2020               Chocolate - Feathers    2755        Sisophon\n11 35 23/7/2020              Pie Filling - Pumpkin    1213    Tlogotunggal\n   product_type\n1          gold\n2       regular\n3          gold\n4       premiun\n5          gold\n6       regular\n7          gold\n8       premiun\n9          gold\n10         gold\n11      regular\n\n\n\nmean_revenue <- round(mean(datos$revenue, na.rm = TRUE),0)\ndatos %>% replace_na(list(revenue = mean_revenue)) %>% slice(25:35)\n\n   id      date                            product revenue            city\n1  25 11/8/2020                               <NA>    1723         Gaocang\n2  26 5/10/2020           Chocolate Bar - Smarties    1969           Rizal\n3  27  6/9/2020                  Tea - Decaf 1 Cup    4202        Mrganush\n4  28  9/3/2020           Bread - Multigrain, Loaf    1190 Aveiras de Cima\n5  29 27/5/2020                Lamb Rack - Ontario    4605          Paihia\n6  30 14/3/2020        Chocolate - Mi - Amere Semi    3540          Lañgub\n7  31 18/8/2020              Cheese - Gouda Smoked    3058            <NA>\n8  32  2/5/2020               Apple - Granny Smith    4848      Cineumbeuy\n9  33 14/5/2020 Chocolate - Liqueur Cups With Foil    1607         Borjomi\n10 34 17/3/2020               Chocolate - Feathers    2755        Sisophon\n11 35 23/7/2020              Pie Filling - Pumpkin    1213    Tlogotunggal\n   product_type\n1          gold\n2       regular\n3          gold\n4       premiun\n5          gold\n6       regular\n7          gold\n8       premiun\n9          gold\n10         gold\n11      regular\n\n\nSi quisiéramos reemplazar todos los NAs de los datos numéricos por un 0, realmente específicar este valor para cada variable puede resultar tedioso. Por tanto, podemos usar un método para modificar todas las columnas numéricas de una vez, tal como se explica en los comentarios del siguiente código.\nPasos:\n\nSelecciono la tabla con que voy a trabajar\nEsta función es como “select” pero con condiciones. En este caso le pido que se quede con las columnas solo si son numéricas.\nUso la función replace y no replace_na, ya que la segunda siempre recibe una lista, y ésta es más directa. Tengo que indicarle una condición y luego el valor con qué reemplazar.\nFinalmente, vuelvo a pegarle las variables que le quité. Puedo usar select_if nuevamente pero esta vez con la condición negativa.\n\n\ndatos %>% # Paso 1\n  select_if(is.numeric) %>% # Paso 2\n  replace(is.na(.),0) %>% # Paso 3\n  cbind(select_if(datos, negate(is.numeric))) %>% # Paso 4\n  slice(25:35)\n\n   id revenue      date                            product            city\n1  25    1723 11/8/2020                               <NA>         Gaocang\n2  26    1969 5/10/2020           Chocolate Bar - Smarties           Rizal\n3  27    4202  6/9/2020                  Tea - Decaf 1 Cup        Mrganush\n4  28    1190  9/3/2020           Bread - Multigrain, Loaf Aveiras de Cima\n5  29    4605 27/5/2020                Lamb Rack - Ontario          Paihia\n6  30    3540 14/3/2020        Chocolate - Mi - Amere Semi          Lañgub\n7  31       0 18/8/2020              Cheese - Gouda Smoked            <NA>\n8  32    4848  2/5/2020               Apple - Granny Smith      Cineumbeuy\n9  33    1607 14/5/2020 Chocolate - Liqueur Cups With Foil         Borjomi\n10 34    2755 17/3/2020               Chocolate - Feathers        Sisophon\n11 35    1213 23/7/2020              Pie Filling - Pumpkin    Tlogotunggal\n   product_type\n1          gold\n2       regular\n3          gold\n4       premiun\n5          gold\n6       regular\n7          gold\n8       premiun\n9          gold\n10         gold\n11      regular\n\n\nEsto podemos aplicarlo con las variables categóricas también, por ejemplo, si queremos que los NAs sean “sin dato” o de algún valor que nos interese. Para esto vamos a necesitar un paquete para el tratamiento de valores de factores, llamada forcats. Este paquete tiene una función dedicada expresamente para sustituir los NAs por otro valor, el truco es reemplazar las variable existente con la nueva generada a través de mutate. Si en vez de factores, trabajáramos con caracteres, la función replace debería ser suficiente.\n\nlibrary(forcats)\ndatos %>% \n  mutate(\n  date = fct_explicit_na(date, \"1/1/1900\"),\n  product = fct_explicit_na(product, \"sinDato\"),\n  city = fct_explicit_na(city, \"Otro\"),\n  product_type = fct_explicit_na(product_type, \"Otro\") ) %>% \n  head()\n\n  id      date                      product revenue         city product_type\n1  1 26/3/2020     Lettuce - Belgian Endive    3139        Laxey      premiun\n2  2 27/5/2020     Table Cloth 91x91 Colour    4726 Svyetlahorsk      regular\n3  3 24/6/2020                   Pur Source    3117      Cabuyao         Otro\n4  4 10/7/2020 Syrup - Monin - Blue Curacao    2575   Nouakchott      regular\n5  5 22/7/2020               Steamers White    3136       Timrat         gold\n6  6 11/3/2020       Wine - Delicato Merlot    1939    Glinojeck         gold\n\n\n\ndatos_sin_na <- datos %>% \n  select_if(is.numeric) %>% # Paso 2\n  replace(is.na(.),0) %>% # Paso 3\n  cbind(select_if(datos, negate(is.numeric))) %>% \n  mutate(\n    date = fct_explicit_na(date, \"1/1/1900\"),\n    product = fct_explicit_na(product, \"sinDato\"),\n    city = fct_explicit_na(city, \"Otro\"),\n    product_type = fct_explicit_na(product_type, \"Otro\") \n  )\n  \nsummary(datos_sin_na)\n\n       id            revenue            date    \n Min.   :   1.0   Min.   :   0   1/1/1900 : 19  \n 1st Qu.: 250.8   1st Qu.:1959   4/11/2020:  9  \n Median : 500.5   Median :3010   13/1/2021:  8  \n Mean   : 500.5   Mean   :2988   15/2/2020:  8  \n 3rd Qu.: 750.2   3rd Qu.:4072   19/7/2020:  7  \n Max.   :1000.0   Max.   :4999   29/5/2020:  7  \n                                 (Other)  :942  \n                      product            city      product_type\n sinDato                  : 49   Otro      : 23   gold   :302  \n Danishes - Mini Raspberry:  5   Guadalupe :  3   premiun:325  \n Cake - Bande Of Fruit    :  4   København :  3   regular:321  \n Beef - Tongue, Cooked    :  3   Buenavista:  2   Otro   : 52  \n Beer - Upper Canada Lager:  3   Cabrobó   :  2                \n Bouillion - Fish         :  3   Córdoba   :  2                \n (Other)                  :933   (Other)   :965"
  },
  {
    "objectID": "chapters/data_manipulation.html#manejo-de-duplicados",
    "href": "chapters/data_manipulation.html#manejo-de-duplicados",
    "title": "5  Manipulación de datos",
    "section": "5.3 Manejo de duplicados",
    "text": "5.3 Manejo de duplicados\nLos duplicados también suelen ser vistos como errores en los datos, pero tal como se aclara en la cita de más arriba, debe tenerse en cuenta el contenido conceptual de cada dataset para dirimir qué hacer con estos casos.\nLos duplicados pueden no serlo de forma absoluta, puede ocurrir que haya duplicados parciales, es decir que se encuentren una serie de variables con el mismo elemento pero en otras no. Dependerá de cada caso si se eliminan, agrupan, o dejan tal cual están.\nPara quedarnos con los valores únicos de un dataset, debemos usar la función distinct. A esta función se le indica a partir de cuáles variables debe buscar que haya combinaciones únicas. Si no se le presentan argumentos, considera a todas las variables.\n\ndatos %>% \n  nrow(.)\n\n[1] 1000\n\ndatos %>% \n  distinct() %>% \n  nrow(.)\n\n[1] 1000\n\n\nAmbos resultados dan mil casos, por tanto, se puede concluir que el dataset no tiene duplicados si tomamos en cuenta todas sus variables. Pero si se toman algunas esto empieza a ocurrir.\nComo puede apreciarse en los cuadros inferiores, si nos quedamos con menos variables, el distinct nos devuelve la cantidad de combinaciones únicas de éstas. También vemos que el uso del distinct indicándole cuáles variable son de interés, nos hace llegar al mismo objetivo.\n\ndatos %>%\n  select(city, product_type) %>% \n  nrow(.)\n\n[1] 1000\n\ndatos %>% \n  select(city, product_type) %>% \n  distinct() %>% \n  nrow(.)\n\n[1] 969\n\ndatos %>% \n  distinct(city, product_type) %>% \n  nrow(.)\n\n[1] 969\n\n\nPor defecto al indicarle cuáles variables nos interesa obtener los valores únicos, el distinct elimina el resto, pero podemos evitar esto si le agregamos el parámetro keep_all. Debe tenerse presente que distinct solo se quedará con el primer registro. Si nuestra intención es que esto sea diferente, debemos ordenar el dataframe de la forma en que elimine los registros que nosotros querramos.\n\ndatos %>% \n  distinct(city, product_type) %>% \n  head()\n\n          city product_type\n1        Laxey      premiun\n2 Svyetlahorsk      regular\n3      Cabuyao         <NA>\n4   Nouakchott      regular\n5       Timrat         gold\n6    Glinojeck         gold\n\ndatos %>% \n  distinct(city, product_type, .keep_all = TRUE) %>% \n  head()\n\n  id      date                      product revenue         city product_type\n1  1 26/3/2020     Lettuce - Belgian Endive    3139        Laxey      premiun\n2  2 27/5/2020     Table Cloth 91x91 Colour    4726 Svyetlahorsk      regular\n3  3 24/6/2020                   Pur Source    3117      Cabuyao         <NA>\n4  4 10/7/2020 Syrup - Monin - Blue Curacao    2575   Nouakchott      regular\n5  5 22/7/2020               Steamers White    3136       Timrat         gold\n6  6 11/3/2020       Wine - Delicato Merlot    1939    Glinojeck         gold"
  },
  {
    "objectID": "chapters/data_manipulation.html#manejo-de-fechas",
    "href": "chapters/data_manipulation.html#manejo-de-fechas",
    "title": "5  Manipulación de datos",
    "section": "5.4 Manejo de fechas",
    "text": "5.4 Manejo de fechas\n\nTipo de dato fecha\nAsí como los factores y los caracteres tienen sus particularidades, suelen dar menos problemas que las fechas, las cuales están condicionadas por formatos. Para manejar este tipo de dato, el paquete más usado se llama lubridate.\nMuchas veces R interpreta las fechas como textos en la medida que el formato no es el mismo que el estandarizado (YYYY-MM-DD). Cuando esto ocurre, debemos transformar la variable con, por ejemplo, una función de lubridate que transforma una variable en fecha, asignándole a cada valor de la fecha el del orden de la función.\nEn este caso usaremos dmy ya que en nuestra variable el formato es DD/MM/YYYY. Si fuera, por ejemplo, MM-DD-AAAA, podríamos usar mdy (no es relevante el simbolo que separe a los elementos de la fecha). Hay también funciones que contienen horas, minutos y segundos.\n\nlibrary(lubridate)\ndatos %>% str(.)\n\n'data.frame':   1000 obs. of  6 variables:\n $ id          : int  1 2 3 4 5 6 7 8 9 10 ...\n $ date        : Factor w/ 341 levels \"1/1/2021\",\"1/10/2020\",..: 210 223 190 21 169 29 9 79 279 142 ...\n $ product     : Factor w/ 786 levels \"Alize Red Passion\",..: 360 654 526 648 631 733 328 369 420 358 ...\n $ revenue     : int  3139 4726 3117 2575 3136 1939 2283 1444 2158 3853 ...\n $ city        : Factor w/ 954 levels \"‘Uzeir\",\"Agbani\",..: 445 769 107 554 800 258 141 453 327 525 ...\n $ product_type: Factor w/ 3 levels \"gold\",\"premiun\",..: 2 3 NA 3 1 1 1 2 1 1 ...\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  str(.)\n\n'data.frame':   1000 obs. of  6 variables:\n $ id          : int  1 2 3 4 5 6 7 8 9 10 ...\n $ date        : Date, format: \"2020-03-26\" \"2020-05-27\" ...\n $ product     : Factor w/ 786 levels \"Alize Red Passion\",..: 360 654 526 648 631 733 328 369 420 358 ...\n $ revenue     : int  3139 4726 3117 2575 3136 1939 2283 1444 2158 3853 ...\n $ city        : Factor w/ 954 levels \"‘Uzeir\",\"Agbani\",..: 445 769 107 554 800 258 141 453 327 525 ...\n $ product_type: Factor w/ 3 levels \"gold\",\"premiun\",..: 2 3 NA 3 1 1 1 2 1 1 ...\n\n\n\n\nGeneración de variables de fechas\nTambién podemos generar variables a partir de fechas, por ejemplo podemos obtener el año, mes y día de la semana a partir de una fecha dada. También, podemos imputar una fecha en específico, por ejemplo, la de hoy.\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(\n    anio = year(date),\n    mes = month(date),\n    dia_semana = wday(date, label = TRUE),\n    hoy = today()\n  ) %>% \n  head()\n\n  id       date                      product revenue         city product_type\n1  1 2020-03-26     Lettuce - Belgian Endive    3139        Laxey      premiun\n2  2 2020-05-27     Table Cloth 91x91 Colour    4726 Svyetlahorsk      regular\n3  3 2020-06-24                   Pur Source    3117      Cabuyao         <NA>\n4  4 2020-07-10 Syrup - Monin - Blue Curacao    2575   Nouakchott      regular\n5  5 2020-07-22               Steamers White    3136       Timrat         gold\n6  6 2020-03-11       Wine - Delicato Merlot    1939    Glinojeck         gold\n  anio mes dia_semana        hoy\n1 2020   3     jue\\\\. 2022-11-28\n2 2020   5     mié\\\\. 2022-11-28\n3 2020   6     mié\\\\. 2022-11-28\n4 2020   7     vie\\\\. 2022-11-28\n5 2020   7     mié\\\\. 2022-11-28\n6 2020   3     mié\\\\. 2022-11-28\n\n\nOtro valor que traen las fechas es la generación de variables calculadas a partir de fechas. Es muy común querer obtener el tiempo transcurrido entre una fecha y otra. En el siguiente ejemplo se presenta cómo encontrar la diferencia en días, meses y años. Es básicamente la división entre la cantidad de días (unidad de medida de lubridate) por el segmentador que nos interesa. El uso de los % es para que redondee.\n\ndatos %>% \n  select(id, date) %>% \n  mutate(date = dmy(date), hoy = today()) %>%\n  mutate(\n    anios_dif = interval(date, hoy) %/% years(1),\n    meses_dif = interval(date, hoy) %/% months(1),\n    dias_dif = interval(date, hoy) %/% days(1),\n    un_anio_mas = date + years(1),\n    un_mes_mas = date + months(1),\n    un_dia_mas = date + 1\n  ) %>% \n  head()\n\n  id       date        hoy anios_dif meses_dif dias_dif un_anio_mas un_mes_mas\n1  1 2020-03-26 2022-11-28         2        32      977  2021-03-26 2020-04-26\n2  2 2020-05-27 2022-11-28         2        30      915  2021-05-27 2020-06-27\n3  3 2020-06-24 2022-11-28         2        29      887  2021-06-24 2020-07-24\n4  4 2020-07-10 2022-11-28         2        28      871  2021-07-10 2020-08-10\n5  5 2020-07-22 2022-11-28         2        28      859  2021-07-22 2020-08-22\n6  6 2020-03-11 2022-11-28         2        32      992  2021-03-11 2020-04-11\n  un_dia_mas\n1 2020-03-27\n2 2020-05-28\n3 2020-06-25\n4 2020-07-11\n5 2020-07-23\n6 2020-03-12"
  },
  {
    "objectID": "chapters/data_manipulation.html#desafío-1",
    "href": "chapters/data_manipulation.html#desafío-1",
    "title": "5  Manipulación de datos",
    "section": "5.5 Desafío",
    "text": "5.5 Desafío\n\nGenere una tabla que muestre el total de productos vendidos, y el total revenue por año y mes. Elimine los casos en donde haya valores faltantes.\n¿Cuáles han sido, para cada año, los cinco productos menos vendidos? ¿Y los menos rentables?\n\n¿Cuántos días han pasado desde que se vendieron estos productos con respecto a la última fecha registrada?\n\nInvestigue si se vende más caro en la primera mitad del año o en la segunda, averiguando el promedio de venta por unidad. Convierta los valores faltantes del mes en enero.\n\n\n\nPosible solución\n# Ejercicio 1\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date), mes = month(date)) %>% \n  drop_na(any_of(c(\"anio\", \"mes\"))) %>% \n  group_by(anio, mes) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE))\n\n# Ejercico 2\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date)) %>% \n  drop_na(any_of(c(\"anio\", \"product\"))) %>% \n  group_by(anio, product) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>%   arrange(cantidad) %>% \n  head(5)\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date)) %>% \n  drop_na(any_of(c(\"anio\", \"product\"))) %>% \n  group_by(anio, product) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>%   arrange(total_ingreso) %>% \n  head(5)\n\n# Ejercicio 2 parte b\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date)) %>% \n  drop_na(any_of(c(\"anio\", \"product\"))) %>% \n  group_by(anio, product) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>% \n  arrange(total_ingreso) %>% \n  head(1) %>% \n  select(product) %>% \n  left_join(datos, by = 'product') %>% \n  mutate(date = dmy(date), hoy = today()) %>% \n  arrange(desc(date)) %>% \n  mutate(dias_desde_que_se_vendio = interval(date, hoy) %/% days(1)) %>% \n  select(product, dias_desde_que_se_vendio) %>% \n  head()\n\n# Ejercicio 3\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(mes = month(date)) %>%\n  replace_na(list(mes = 1)) %>% \n  mutate(\n    parte_del_anio = case_when(\n      mes < 7 ~ \"Primera parte\",\n      mes > 6 ~ \"Segunda parte\"\n    )\n  ) %>% \n  group_by(parte_del_anio) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>%\n  mutate(promedio_venta = total_ingreso/cantidad)"
  },
  {
    "objectID": "chapters/visualization.html",
    "href": "chapters/visualization.html",
    "title": "6  Visualización de datos",
    "section": "",
    "text": "R y en particular RStudio son herramientas muy útiles para la visualización de datos. El paquete más relevante para esta cuestión es ggplot. Este paquete tiene una estructura muy particular pero clara a la hora de generar visualizaciones.\nPara visualizar esto, vamos a trabajar con el dataset implícito de R, iris.\n\niris <- iris\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nEste dataset contiene información sobre distintas flores, como la longitud y anchura de sus pétalos, sépalos y la especie. La función ggplot genera un canva en donde se despliega la gráfica. Si tan solo se llama a la función, podemos ver desplegado este espacio vacío.\n\nlibrary(ggplot2)\nlibrary(tidyverse)\niris %>% \n  ggplot()\n\n\n\n\nPara poder visualizar lo que hay dentro, debemos dentro de la función ggplot delinear el eje x e y (este último es opcional). Por ejemplo, podemos querer generar un gráfico que muestre en barras la cantidad de casos por especie. Para empezar, podemos definir el eje x con las especies, mediante la función aes.\n\niris %>% \n  ggplot(aes(x = Species))\n\n\n\n\nVemos que aparece en el eje x los distintos valores de la variable de especies, junto con el nombre de la variable como título del eje. Ahora resta agregar el tipo de gráfico que queremos mostrar. Para esto, debemos agregarle un elemento concatenado a la función ggplot, que le indica el tipo de gráfico. Por ejemplo, para un gráfico de barras, hay que agregar geom_bar.\n\niris %>% \n  ggplot(aes(x = Species)) +\n  geom_bar()\n\n\n\n\nPor defecto, el geom_bar hace un conteo de valores de cada elemento de la variable y eso es lo que grafica. En este caso, cada elemento tiene 50 casos y es por eso que los despliega iguales. A su vez, el eje refleja la métrica utilizada. Si quisiéramos editar los ejes hay que hacer otra concatenación donde se los indiquemos.\n\niris %>% \n  ggplot(aes(x = Species)) +\n  geom_bar() +\n  labs(\n    title = \"Cantidad de especies\",\n    x = \"Especies\",\n    y = \"Cantidad\"\n  )\n\n\n\n\nTambién pueden agregarse otros elementos estéticos al gráfico, como las etiquetas de datos y los colores de las gráficas. Con respecto a las etiquetas, con la función geom_text suele bastar con agregar label = variable_en_eje_y pero como en éste caso no hay, es un poco más complejo. El parámetro just varía según si es vertical u horizontal, y refiere a la ubicación. Si cambiamos el valor, cambia donde queda la etiqueta.\n\niris %>% \n  ggplot(aes(x = Species)) +\n  geom_bar(fill = 'lightgreen') +\n  labs(\n    title = \"Cantidad de especies\",\n    x = \"Especies\",\n    y = \"Cantidad\"\n  ) +\n  geom_text(aes(label = ..count..), stat = \"count\", vjust = -0.5)\n\n\n\n\nFinalmente, pueden seleccionarse temas dentro de ggplot que permiten una mejora visual de todos los elementos del gráfico. Hay muchos para elegir y pueden aportar mucho en términos de visualización.\n\niris %>% \n  ggplot(aes(x = Species)) +\n  geom_bar(fill = 'lightgreen') +\n  labs(\n    title = \"Cantidad de especies\",\n    x = \"Especies\",\n    y = \"Cantidad\"\n  ) +\n  geom_text(aes(label = ..count..), stat = \"count\", vjust = -0.5) +\n  theme_bw()"
  },
  {
    "objectID": "chapters/visualization.html#tipos-de-gráfico",
    "href": "chapters/visualization.html#tipos-de-gráfico",
    "title": "6  Visualización de datos",
    "section": "6.2 Tipos de gráfico",
    "text": "6.2 Tipos de gráfico\n\nDe barras horizontales\nYa vimos cómo generar un gráfico de barras clásico, pero a veces resulta conveniente tenerlas de forma horizontal. Para esto, se puede usar la función coord_flip.\n\niris %>% \n  ggplot(aes(x = Species)) +\n  geom_bar(fill = 'darkblue') +\n  labs(\n    title = \"Cantidad de especies\",\n    x = \"Especies\",\n    y = \"Cantidad\"\n  ) +\n  geom_text(aes(label = ..count..), stat = \"count\", hjust = -0.5) +\n  coord_flip() +\n  theme_bw()\n\n\n\n\nCuando queremos graficar ciertos datos, conviene previamente armar una tabla que permita simplemente representar los resultados. Si bien ggplot puede elaborarse a partir de cálculos con el dataset entero, conviene dejarle los números dados.\n\niris %>% \n  group_by(Species) %>% \n  summarise(promedio_largo_hojas = mean(Petal.Length)) %>% \n  ggplot(aes(x = Species, y = promedio_largo_hojas)) +\n  geom_bar(stat = 'identity') +\n    labs(\n    title = \"Promedio del largo del pétalo\",\n    x = \"Especies\",\n    y = \"\"\n  ) + \n  geom_text(aes(label = promedio_largo_hojas), vjust = -0.5) +\n  theme_bw()\n\n\n\n\n\n\nBarras acumuladas\nLas barras acumuladas implican tener que pasarle una variable a ggplot para que acumule. Si realizamos un summarise, éste naturalmente nos devolvera una columna por cada cálculo. Tenemos que adaptarlo a las necesidades de ggplot mediante la función gather, que sirve para hacer un despivotamiento de columnas.\nUn despivotamiento de columnas es básicamente pasar una serie de columnas a tan solo dos: una que sea el concepto y otra el valor, y duplicar filas para no perder información.\n\niris %>% \n  group_by(Species) %>% \n  summarise(\n    promedio_largo_hojas = mean(Petal.Length),\n    promedio_ancho_hojas = mean(Petal.Width)\n  ) %>% \n  gather(\"concepto\", \"valor\", 2:3) %>% \n  ggplot(aes(x= Species, y = valor, fill = concepto)) +\n  geom_bar(stat = 'identity') +\n  theme_bw()\n\n\n\n\nEste método se debe usar tanto para acumulación de barras como al usarlas en posición dodge.\n\niris %>% \n  group_by(Species) %>% \n  summarise(\n    promedio_largo_hojas = mean(Petal.Length),\n    promedio_ancho_hojas = mean(Petal.Width)\n  ) %>% \n  gather(\"concepto\", \"valor\", 2:3) %>% \n  ggplot(aes(x= Species, y = valor, fill = concepto)) +\n  geom_bar(stat = 'identity',position = position_dodge()) +\n  theme_bw()\n\n\n\n\n\n\nGráficos de dispersión\nLos gráficos de dispersión son básicos en cualquier análisis cuantitativo. Se pueden generar fácilmente con ggplot y además agregar variables categóricas para segmentar. Finalmente la función que se utiliza es geom_point().\n\niris %>% \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\nHistogramas\nPara realizar tanto histogramas como boxplot, es camino es bastante directo.\n\niris %>% \n  ggplot(aes(x = Sepal.Length)) +\n  geom_histogram() +\n  theme_bw()\n\n\n\n\n\n\nBoxplot\nSi bien la estructura de ggplot es sencilla, es muy personalizable de acuerdo a lo que necesite el analista.\n\niris %>% \n  ggplot(aes(x = Species, y = Sepal.Length)) +\n  geom_boxplot() +\n  theme_bw()\n\n\n\n\nSi quieren conocer a fondo las cuestiones de visualización y ver más tipos de gráficos, recomiendo este libro."
  },
  {
    "objectID": "chapters/visualization.html#desafío",
    "href": "chapters/visualization.html#desafío",
    "title": "6  Visualización de datos",
    "section": "6.3 Desafío",
    "text": "6.3 Desafío\nObtenga el dataset “datos_ventas” y realice las siguientes operaciones:\n\nGenere una gráfica de barras verticales que muestre la cantidad de ventas (filas) que hubo por color de producto.\nGenere un gráfico de barras horizontales que muestre el total de ingreso por departamento.\nInvestigue cómo generar un gráfico de lineas que le permita hacer una evolución de las ganancias.\n\n\nCuidado con los NAs\nCada gráfico debe tener una temática junto con sus nombres de ejes y etiquetas.\n\n\n\nPosible solución\nlibrary(openxlsx)\nventas <- read.xlsx(\"../data/Chapter_6/data_c_1.xlsx\", detectDates = TRUE)\n\n# Primer ejercicio\n\nventas %>% \n  group_by(Color) %>% \n  summarise(ventas = n()) %>% \n  ggplot(aes(x = Color, y = ventas)) +\n  geom_col() +\n  labs(\n    title = \"Cantidad de ventas por color\",\n    x = \"\",\n    y = \"\"\n  ) +\n  geom_text(aes(label = ventas), vjust = -0.5) +\n  theme_bw()\n\n# Segundo ejercicio\n\nventas %>% \n  mutate(ingreso = Cantidad * Monto) %>% \n  group_by(Departamento) %>% \n  summarise(ingreso = sum(ingreso, na.rm = TRUE)) %>% \n  ggplot(aes(x = Departamento, y = ingreso)) +\n  geom_bar(stat = 'identity') +\n  labs(\n    title = \"Ingreso total por departamento\",\n    x = \"\", \n    y = \"\"\n  ) +\n  coord_flip() +\n  geom_text(aes(label = ingreso), hjust = 1.1, color = 'white') +\n  theme_bw()\n\n# Tercer ejercicio\n\nventas %>% \n  mutate(ingreso = Cantidad * Monto) %>% \n  group_by(Fecha) %>% \n  summarise(ingreso = sum(ingreso, na.rm = TRUE)) %>% \n  ggplot(aes(x = Fecha, y = ingreso)) +\n  geom_line() +\n  labs(\n    title = \"Evolución de la ganancia\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_bw()"
  },
  {
    "objectID": "chapters/data_analisis.html#manipulación-del-dataframe",
    "href": "chapters/data_analisis.html#manipulación-del-dataframe",
    "title": "4  Análisis de datos",
    "section": "4.2 Manipulación del dataframe",
    "text": "4.2 Manipulación del dataframe\nPara obtener los datos, podemos utilizar algunas de las funciones que hemos visto en el curso. En este caso utilizaremos un dataset con datos sobre salarios de diversas instituciones de salud.\n\ndf <- read_csv(\"../data/Chapter_4/data_c_1.csv\")\n\n\nglimpse(df)\n\nRows: 623\nColumns: 10\n$ institucion      <chr> \"ASFE\", \"ASFE\", \"ASFE\", \"Blue Light\", \"St. Mokaroo\", ~\n$ sexo             <chr> \"M\", \"M\", \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"M\", \"M\"~\n$ fecha_nacimiento <chr> \"24/08/1990\", \"11/04/1984\", \"07/10/1986\", \"12/01/1986~\n$ cod_persona      <chr> \"31-054-1896\", \"93-328-1614\", \"83-633-7650\", \"74-256-~\n$ nombre           <chr> \"Alonso\", \"Bernhard\", \"Kalina\", \"Nettie\", \"Guillema\",~\n$ apellido         <chr> \"Syddall\", \"Ebbotts\", \"Rapps\", \"Merner\", \"Loges\", \"Ba~\n$ area             <chr> \"Training\", \"Training\", \"Human Resources\", \"Business ~\n$ salario          <dbl> 3883, 3304, 2493, 3638, 469, 627, 4066, 2037, 2397, 8~\n$ mail             <chr> \"asyddall0@topsy.com\", \"bebbotts1@plala.or.jp\", \"krap~\n$ socio            <dbl> 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,~\n\n\nParece ser que nuestro dataset tiene muchas variables que no utilizaremos. Una de las funciones que tidyverse provee nos permite seleccionar rápidamente las columnas con las que vamos a trabajar. Esta función se llama select. Para usar esta función ponemos como primer parámetro el nombre del dataset que vamos a filtrar, y luego los nombres de las columnas que nos interesan.\n\ndf_filtrado <- select(\n  df, institucion, sexo, fecha_nacimiento, cod_persona, area, salario, socio\n)\nstr(df_filtrado)\n\ntibble [623 x 7] (S3: tbl_df/tbl/data.frame)\n $ institucion     : chr [1:623] \"ASFE\" \"ASFE\" \"ASFE\" \"Blue Light\" ...\n $ sexo            : chr [1:623] \"M\" \"M\" \"F\" \"F\" ...\n $ fecha_nacimiento: chr [1:623] \"24/08/1990\" \"11/04/1984\" \"07/10/1986\" \"12/01/1986\" ...\n $ cod_persona     : chr [1:623] \"31-054-1896\" \"93-328-1614\" \"83-633-7650\" \"74-256-9143\" ...\n $ area            : chr [1:623] \"Training\" \"Training\" \"Human Resources\" \"Business Development\" ...\n $ salario         : num [1:623] 3883 3304 2493 3638 469 ...\n $ socio           : num [1:623] 1 0 0 1 1 1 1 0 0 1 ...\n\n\nAhora tenemos un dataframe más manejable. Siempre es recomendable quedarse con las columnas que se utilizarán para el análisis, tanto por un tema de facilidad de comprensión del dataset como por el uso de memoria del computador.\nLa función select se encuentra dentro del paquete dplyr, que a su vez está dentro de tidyverse. Este paquete permite el uso de pipes (%>%) para concatenar una serie de actos con el dataframe. No es obligación usarlo, pero sirve para ordenar una serie de acciones que querremos realizar sobre los datos.\nSe puede usar de la siguiente manera:\n\ndf_filtrado <- df %>% \n  select(\n    institucion, sexo, fecha_nacimiento, cod_persona, area, salario, socio\n  )\n\nComo vemos, de esta forma obtenemos el mismo resultado. Lo que hacemos es decirle a R que a partir de ahora trabajaremos con el dataset df y que todo lo que viene a continuación va a ser en relación a esa tabla. Por tanto, a partir de ahí no habrá que usar los $ para referirse a las columnas, simplemente dará por hecho que son del dataframe. Esto sucede con todas las funciones de tidyverse que se usen con los pipes.\nOtro tipo de filtro que podemos querer realizar es hacia las filas. Anteriormente se ha visto que pueden seleccionarse filtras manualmente aclarando el número de fila y demás, pero por lo general resulta más conveniente filtrar en base a una condición. Por ejemplo, veamos qué organizaciones tenemos en el dataset.\n\nunique(df_filtrado$institucion)\n\n[1] \"ASFE\"            \"Blue Light\"      \"St. Mokaroo\"     \"RedHat Hospital\"\n\n\nVamos a querer trabajar con los registros de ASFE, por tanto, podemos usar funciones de tidyverse para realizar esta tarea. Crearemos un nuevo dataset denominado df_filtrado_asfe en donde solo almacenaremos registros de esta entidad.\n\ndf_filtrado_asfe <- df_filtrado %>% \n  filter(institucion == 'ASFE')\n\nhead(df_filtrado_asfe)\n\n# A tibble: 6 x 7\n  institucion sexo  fecha_nacimiento cod_persona area              salario socio\n  <chr>       <chr> <chr>            <chr>       <chr>               <dbl> <dbl>\n1 ASFE        M     24/08/1990       31-054-1896 Training             3883     1\n2 ASFE        M     11/04/1984       93-328-1614 Training             3304     0\n3 ASFE        F     07/10/1986       83-633-7650 Human Resources      2493     0\n4 ASFE        F     19/04/1982       04-065-8324 Services              627     1\n5 ASFE        M     07/09/1986       49-644-6789 Marketing            2397     0\n6 ASFE        M     08/06/1990       66-578-6374 Product Manageme~     287     1\n\n\nPodemos usar el select no solo para elegir las variables que queremos sino también para desechar las que no nos interesan. Por ejemplo, ahora tenemos un dataset que solo tiene registros de MP, por tanto la variable con el nombre de institución nos aporta poco, por lo que podemos quitarla.\n\ndf_filtrado_asfe <- df_filtrado_asfe %>% select(-institucion)\nhead(df_filtrado_asfe)\n\n# A tibble: 6 x 6\n  sexo  fecha_nacimiento cod_persona area               salario socio\n  <chr> <chr>            <chr>       <chr>                <dbl> <dbl>\n1 M     24/08/1990       31-054-1896 Training              3883     1\n2 M     11/04/1984       93-328-1614 Training              3304     0\n3 F     07/10/1986       83-633-7650 Human Resources       2493     0\n4 F     19/04/1982       04-065-8324 Services               627     1\n5 M     07/09/1986       49-644-6789 Marketing             2397     0\n6 M     08/06/1990       66-578-6374 Product Management     287     1\n\n\nEl último detalle que se le puede hacer al dataframe para que quede perfecto es cambiarle algunos nombres para que reflejen mejor el contenido de las variables. En este caso vamos a querer modificar los nombres de columna de cod_persona a documento y socio a es_accionista. Podemos hacerlo con la función rename. Debemos aclararle el nuevo nombre de la variable y el nombre de la que vamos a sustituir. Se puede usar para varias columnas a la vez.\n\ndf_filtrado_asfe <- df_filtrado_asfe %>% \n  rename(\n    documento = cod_persona,\n    es_accionista = socio\n  )\n\nhead(df_filtrado_asfe)\n\n# A tibble: 6 x 6\n  sexo  fecha_nacimiento documento   area               salario es_accionista\n  <chr> <chr>            <chr>       <chr>                <dbl>         <dbl>\n1 M     24/08/1990       31-054-1896 Training              3883             1\n2 M     11/04/1984       93-328-1614 Training              3304             0\n3 F     07/10/1986       83-633-7650 Human Resources       2493             0\n4 F     19/04/1982       04-065-8324 Services               627             1\n5 M     07/09/1986       49-644-6789 Marketing             2397             0\n6 M     08/06/1990       66-578-6374 Product Management     287             1\n\n\nYa tenemos el dataframe tal cual como queremos, pero el verdadero poder de tidyverse radica en la concatenación de pipes para alcanzar el objetivo en una sola orden a R. Podemos obtener el mismo dataframe que nos llevó todo este laboratorio de la siguiente manera:\n\ndf_filtrado_asfe <- df %>% \n  select(institucion, sexo, fecha_nacimiento, cod_persona, area, salario, socio) %>% \n  filter(institucion == 'ASFE') %>% \n  select(-institucion) %>% \n  rename(documento = cod_persona, es_accionista = socio)\n  \nhead(df_filtrado_asfe)\n\n# A tibble: 6 x 6\n  sexo  fecha_nacimiento documento   area               salario es_accionista\n  <chr> <chr>            <chr>       <chr>                <dbl>         <dbl>\n1 M     24/08/1990       31-054-1896 Training              3883             1\n2 M     11/04/1984       93-328-1614 Training              3304             0\n3 F     07/10/1986       83-633-7650 Human Resources       2493             0\n4 F     19/04/1982       04-065-8324 Services               627             1\n5 M     07/09/1986       49-644-6789 Marketing             2397             0\n6 M     08/06/1990       66-578-6374 Product Management     287             1"
  },
  {
    "objectID": "chapters/data_analisis.html#transformación-de-datos",
    "href": "chapters/data_analisis.html#transformación-de-datos",
    "title": "4  Análisis de datos",
    "section": "4.3 Transformación de datos",
    "text": "4.3 Transformación de datos\nTidyverse también nos provee funciones para agregar y modificar columnas. Estas funciones son mutate y transmute. Mutate permite agregar una columna nueva al dataframe. Transmute hace lo mismo pero además elimina el resto de las columnas, permitiendo hacer un select implícito.\nPara empezar, vamos a querer volver a tener una variable que idenfique la institución, su nombre será institucion y su contenido “Asociación de Salud Federal del Estado”.\n\ndf_columnas <- df_filtrado_asfe %>% \n  mutate(institucion = \"Asociación de Salud Federal del Estado\")\n\nhead(df_columnas)\n\n# A tibble: 6 x 7\n  sexo  fecha_nacimiento documento   area               salario es_acc~1 insti~2\n  <chr> <chr>            <chr>       <chr>                <dbl>    <dbl> <chr>  \n1 M     24/08/1990       31-054-1896 Training              3883        1 Asocia~\n2 M     11/04/1984       93-328-1614 Training              3304        0 Asocia~\n3 F     07/10/1986       83-633-7650 Human Resources       2493        0 Asocia~\n4 F     19/04/1982       04-065-8324 Services               627        1 Asocia~\n5 M     07/09/1986       49-644-6789 Marketing             2397        0 Asocia~\n6 M     08/06/1990       66-578-6374 Product Management     287        1 Asocia~\n# ... with abbreviated variable names 1: es_accionista, 2: institucion\n\n\nNos interesará generar una variable genero que sustituya a la columna sexo y sea el mismo contenido pero en texto. Para esto podemos usar la función if_else. Esta función básicamente realiza el mismo trabajo que la función de excel: le insertamos una condición y luego el siguiente parámetro es el que inserta en caso de que la condición se cumpla, y el siguiente en caso que no. Luego, eliminaremos la variable sexo ya que no la utilizaremos y renombraremos la creada como su original.\n\ndf_columnas <- df_columnas %>% \n  mutate(genero = if_else(sexo == 1, \"Hombre\", \"Mujer\")) %>% \n  select(-sexo) %>% \n  rename(sexo = genero)\n\nhead(df_columnas)\n\n# A tibble: 6 x 7\n  fecha_nacimiento documento   area               salario es_acc~1 insti~2 sexo \n  <chr>            <chr>       <chr>                <dbl>    <dbl> <chr>   <chr>\n1 24/08/1990       31-054-1896 Training              3883        1 Asocia~ Mujer\n2 11/04/1984       93-328-1614 Training              3304        0 Asocia~ Mujer\n3 07/10/1986       83-633-7650 Human Resources       2493        0 Asocia~ Mujer\n4 19/04/1982       04-065-8324 Services               627        1 Asocia~ Mujer\n5 07/09/1986       49-644-6789 Marketing             2397        0 Asocia~ Mujer\n6 08/06/1990       66-578-6374 Product Management     287        1 Asocia~ Mujer\n# ... with abbreviated variable names 1: es_accionista, 2: institucion\n\n\nRealizar esta serie de pasos es con el fin de mostrar el uso del select para eliminar columnas de otra manera que seleccionando las que queremos: seleccionando las que no queremos. Si en mutate se hubiera puesto como nombre de variable sexo, hubiera sustituido a la original.\nEn este caso if_else resulta de utilidad porque la cantidad de condiciones eran pocas. En caso que se sean muchas, empieza a ser ineficiente en la medida que hay que concatenar if_else tras if_else. Para los casos en los que haya muchas posibilidades, es mejor usar case_when.\nPara demostrar el uso de esta función, crearemos una variable que diga si el documento es de menos de un millón, mayor a un millón, mayor a dos millones, a tres, a cuatro, y mayor a cinco. Al final de la función, se le especifica el tipo de dato de la variable resultante.\n\ndf_columnas %>% mutate(\n  franja_salario = case_when(\n    salario > 4000 ~ \"Mayor a cuatro mil\",\n    salario > 3000 ~ \"Mayor a tres mil, menor o igual a cuatro mil\",\n    salario > 2000 ~ \"Mayor a dos mil, menor o igual a tres mil\",\n    salario > 1000 ~ \"Mayor a mil, menor o igual a dos mil\",\n    TRUE ~ \"Menor o igual a mil\"\n  )\n)\n\n# A tibble: 148 x 8\n   fecha_nacimiento documento   area       salario es_ac~1 insti~2 sexo  franj~3\n   <chr>            <chr>       <chr>        <dbl>   <dbl> <chr>   <chr> <chr>  \n 1 24/08/1990       31-054-1896 Training      3883       1 Asocia~ Mujer Mayor ~\n 2 11/04/1984       93-328-1614 Training      3304       0 Asocia~ Mujer Mayor ~\n 3 07/10/1986       83-633-7650 Human Res~    2493       0 Asocia~ Mujer Mayor ~\n 4 19/04/1982       04-065-8324 Services       627       1 Asocia~ Mujer Menor ~\n 5 07/09/1986       49-644-6789 Marketing     2397       0 Asocia~ Mujer Mayor ~\n 6 08/06/1990       66-578-6374 Product M~     287       1 Asocia~ Mujer Menor ~\n 7 02/04/1982       51-105-8497 Research ~    2855       1 Asocia~ Mujer Mayor ~\n 8 11/06/1984       27-296-9259 Legal         3992       1 Asocia~ Mujer Mayor ~\n 9 31/07/1982       60-141-4356 Accounting    1320       0 Asocia~ Mujer Mayor ~\n10 18/04/1986       85-181-4795 Sales         1646       0 Asocia~ Mujer Mayor ~\n# ... with 138 more rows, and abbreviated variable names 1: es_accionista,\n#   2: institucion, 3: franja_salario\n\n\nTal como puede apreciarse, se puede utilizar tidyverse para mostrar resultados en consola. No es necesario almacenar los procesos en objetos.\n\ndf_filtrado_asfe %>% \n  mutate(genero = if_else(sexo == 1, \"Hombre\", \"Mujer\")) %>% \n  select(-sexo) %>% \n  rename(sexo = genero)\n\n# A tibble: 148 x 6\n   fecha_nacimiento documento   area                     salario es_acci~1 sexo \n   <chr>            <chr>       <chr>                      <dbl>     <dbl> <chr>\n 1 24/08/1990       31-054-1896 Training                    3883         1 Mujer\n 2 11/04/1984       93-328-1614 Training                    3304         0 Mujer\n 3 07/10/1986       83-633-7650 Human Resources             2493         0 Mujer\n 4 19/04/1982       04-065-8324 Services                     627         1 Mujer\n 5 07/09/1986       49-644-6789 Marketing                   2397         0 Mujer\n 6 08/06/1990       66-578-6374 Product Management           287         1 Mujer\n 7 02/04/1982       51-105-8497 Research and Development    2855         1 Mujer\n 8 11/06/1984       27-296-9259 Legal                       3992         1 Mujer\n 9 31/07/1982       60-141-4356 Accounting                  1320         0 Mujer\n10 18/04/1986       85-181-4795 Sales                       1646         0 Mujer\n# ... with 138 more rows, and abbreviated variable name 1: es_accionista"
  },
  {
    "objectID": "chapters/data_analisis.html#combinación-de-filtros",
    "href": "chapters/data_analisis.html#combinación-de-filtros",
    "title": "4  Análisis de datos",
    "section": "4.4 Combinación de filtros",
    "text": "4.4 Combinación de filtros\nEn el uso del case_when se pueden generar condiciones combinadas para alcanzar resultados más precisos. En el ejemplo anterior, se utilizó un método que implicaba ir de arriba hacía abajo con el filtro, pero lo más razonable sería combinar filtros para ser más robusto con la condición.\nVamos a pedirle a R que los valore que para cada caso sea mayor que determinado valor, pero también menor al de la siguiente categoría. De este modo no importa el orden de las condiciones, ya que son muy precisas.\n\ndf_columnas %>% mutate(\n  franja_salario = case_when(\n    salario > 4000 ~ \"Mayor a cuatro mil\",\n    salario > 3000 & salario <= 4000 ~ \"Mayor a tres mil, menor o igual a cuatro mil\",\n    salario > 2000 & salario <= 3000 ~ \"Mayor a dos mil, menor o igual a tres mil\",\n    salario > 1000 & salario <= 2000 ~ \"Mayor a mil, menor o igual a dos mil\",\n    TRUE ~ \"Menor o igual a mil\"\n  )\n)\n\n# A tibble: 148 x 8\n   fecha_nacimiento documento   area       salario es_ac~1 insti~2 sexo  franj~3\n   <chr>            <chr>       <chr>        <dbl>   <dbl> <chr>   <chr> <chr>  \n 1 24/08/1990       31-054-1896 Training      3883       1 Asocia~ Mujer Mayor ~\n 2 11/04/1984       93-328-1614 Training      3304       0 Asocia~ Mujer Mayor ~\n 3 07/10/1986       83-633-7650 Human Res~    2493       0 Asocia~ Mujer Mayor ~\n 4 19/04/1982       04-065-8324 Services       627       1 Asocia~ Mujer Menor ~\n 5 07/09/1986       49-644-6789 Marketing     2397       0 Asocia~ Mujer Mayor ~\n 6 08/06/1990       66-578-6374 Product M~     287       1 Asocia~ Mujer Menor ~\n 7 02/04/1982       51-105-8497 Research ~    2855       1 Asocia~ Mujer Mayor ~\n 8 11/06/1984       27-296-9259 Legal         3992       1 Asocia~ Mujer Mayor ~\n 9 31/07/1982       60-141-4356 Accounting    1320       0 Asocia~ Mujer Mayor ~\n10 18/04/1986       85-181-4795 Sales         1646       0 Asocia~ Mujer Mayor ~\n# ... with 138 more rows, and abbreviated variable names 1: es_accionista,\n#   2: institucion, 3: franja_salario"
  },
  {
    "objectID": "chapters/data_analisis.html#agregaciones",
    "href": "chapters/data_analisis.html#agregaciones",
    "title": "4  Análisis de datos",
    "section": "4.5 Agregaciones",
    "text": "4.5 Agregaciones\nCuestión frecuente en el análisis de datos es la de generar tablas agregadas. Para tales usos el tidyverse tiene dos funciones que son clave: group_by y summarise.\nGroup_by, tal como su nombre lo indica, sirve para generar agrupaciones a partir de una variable. Para utilizarla no debemos más que declarar cuál variable queremos utilizar para agrupar.\nLa función summarise, por otra parte, realiza las agregaciones que el analista requiere a partir de la agrupación declarada. Para practicar esto, volveremos a nuestro dataframe filtrado, y realizaremos una agrupación a partir de cada mutualista, mostrando la cantidad de personal para cada una.\n\npersonal_por_institucion <- df_filtrado %>% \n  group_by(institucion) %>% \n  summarise(cantidad = n())\n\npersonal_por_institucion\n\n# A tibble: 4 x 2\n  institucion     cantidad\n  <chr>              <int>\n1 ASFE                 148\n2 Blue Light           156\n3 RedHat Hospital      157\n4 St. Mokaroo          162\n\n\nCuando usamos summarise, se debe elegir el nombre de la(s) columna(s) resumen, y utilizar una función de agregación. Las más clasicas son sum, mean, max, min, etc. Si queremos saber la cantidad de registros, lo que vendría a ser un count, podemos usar la función n también.\nEl dataframe resultante nos muestra la cantidad de registros por cada elemento de la columna institucion. Pero tal como puede apreciarse, el orden de estos elementos está pautado por el orden alfabético de la columna agrupada. Podemos pedirle a R que ordene a partir de otra columna con la función arrange. Esta función ordena por defecto de forma ascendente, si le ponemos desc a la columna, ordena de la otra forma.\n\npersonal_por_institucion <- df_filtrado %>% \n  group_by(institucion) %>% \n  summarise(cantidad = n()) %>% \n  arrange(desc(cantidad))\n\npersonal_por_institucion\n\n# A tibble: 4 x 2\n  institucion     cantidad\n  <chr>              <int>\n1 St. Mokaroo          162\n2 RedHat Hospital      157\n3 Blue Light           156\n4 ASFE                 148\n\n\nAhora que nuestra tabla agregada está ordenada y clara, nos resulta relevante tener la certeza de que refleja la información solicitada. Es decir, si cada registro condice con una persona. Este elemento se denomina perfil del dato y relevante tenerlo claro a la hora de realizar un análisis, ya que en otro caso podemos dar información incorrecta.\nPara asegurarnos de tener la cantidad exacta de personas por institución, debemos tener el recuento de cédulas distintas que hay, por tanto no conteo simple no nos habilita esa posibilidad. Para esto podemos usar la función n_distinct que justamente trae un conteo de los valores únicos para cada columna. A diferencia de n, a n_distinct debemos aclararle con qué columna estamos trabajando. En este caso, el resultado nos dará igual porque hay un solo caso por persona, pero si hubieran duplicados por institución, la cantidad sería menor.\n\npersonal_por_institucion <- df_filtrado %>% \n  group_by(institucion) %>% \n  summarise(cantidad = n_distinct(cod_persona)) %>% \n  arrange(desc(cantidad))\n\npersonal_por_institucion\n\n# A tibble: 4 x 2\n  institucion     cantidad\n  <chr>              <int>\n1 St. Mokaroo          162\n2 RedHat Hospital      157\n3 Blue Light           156\n4 ASFE                 148\n\n\nOtro análisis que podríamos hacer es qué porcentaje del total del personal tiene cada mutualista. Para hacer esto hay que generar una columna nueva luego de hacer la agrupación, podemos usar mutate.\n\npersonal_por_institucion <- df_filtrado %>% \n  group_by(institucion) %>% \n  summarise(cantidad = n_distinct(cod_persona)) %>% \n  arrange(desc(cantidad)) %>% \n  mutate(porcentaje = cantidad / sum(cantidad) * 100)\n\npersonal_por_institucion\n\n# A tibble: 4 x 3\n  institucion     cantidad porcentaje\n  <chr>              <int>      <dbl>\n1 St. Mokaroo          162       26.0\n2 RedHat Hospital      157       25.2\n3 Blue Light           156       25.0\n4 ASFE                 148       23.8\n\n\nEl porcentaje funciona correctamente pero ver tantos decimales aporta poco para el análisis en este caso. Podemos redondear los elementos de las columnas utilizando la función round. Esta función tiene dos parámetros: el número o columna que debe redondear, y la cantidad de decimales que debe permitir. En este caso le pondremos 0.\n\npersonal_por_institucion <- df_filtrado %>% \n  group_by(institucion) %>% \n  summarise(cantidad = n_distinct(cod_persona)) %>% \n  arrange(desc(cantidad)) %>% \n  mutate(porcentaje = round(cantidad / sum(cantidad) * 100,0))\n\nhead(personal_por_institucion)\n\n# A tibble: 4 x 3\n  institucion     cantidad porcentaje\n  <chr>              <int>      <dbl>\n1 St. Mokaroo          162         26\n2 RedHat Hospital      157         25\n3 Blue Light           156         25\n4 ASFE                 148         24\n\n\nTambién es posible realizar agregaciones por más de una variable. Por ejemplo, sería interesante conocer la cantidad de personas por institución pero también a nivel de sexo. Para esto, debemos agrupar por institución y por sexo, y luego sumarisar.\n\npersonal_por_institucion <- df_filtrado %>% \n  group_by(institucion, sexo,) %>% \n  summarise(cantidad = n_distinct(cod_persona))\n\npersonal_por_institucion\n\n# A tibble: 8 x 3\n# Groups:   institucion [4]\n  institucion     sexo  cantidad\n  <chr>           <chr>    <int>\n1 ASFE            F           66\n2 ASFE            M           82\n3 Blue Light      F           84\n4 Blue Light      M           72\n5 RedHat Hospital F           79\n6 RedHat Hospital M           78\n7 St. Mokaroo     F           71\n8 St. Mokaroo     M           91\n\n\n¿Se acuerdan cómo modificamos nuestra variable sexo a una con caracteres y no numérica? Podemos hacer todo en un solo paso para que quede más legible.\n\npersonal_por_institucion <- df_filtrado %>% \n  mutate(sexo_1 = if_else(sexo == \"M\", \"Hombre\", \"Mujer\")) %>% \n  group_by(institucion, sexo_1) %>% \n  summarise(cantidad = n_distinct(cod_persona))\n\npersonal_por_institucion\n\n# A tibble: 8 x 3\n# Groups:   institucion [4]\n  institucion     sexo_1 cantidad\n  <chr>           <chr>     <int>\n1 ASFE            Hombre       82\n2 ASFE            Mujer        66\n3 Blue Light      Hombre       72\n4 Blue Light      Mujer        84\n5 RedHat Hospital Hombre       78\n6 RedHat Hospital Mujer        79\n7 St. Mokaroo     Hombre       91\n8 St. Mokaroo     Mujer        71\n\n\nQuizás no nos interesa verlo en términos de hombre o mujer, y solo nos interesan los hombres. Podemos incorporar un filtro previamente y eso hace el trabajo.\n\npersonal_por_institucion <- df_filtrado %>% \n  filter(sexo == \"M\") %>% \n  group_by(institucion) %>% \n  summarise(cantidad = n_distinct(cod_persona)) %>% \n  arrange(desc(cantidad))\n\nhead(personal_por_institucion)\n\n# A tibble: 4 x 2\n  institucion     cantidad\n  <chr>              <int>\n1 St. Mokaroo           91\n2 ASFE                  82\n3 RedHat Hospital       78\n4 Blue Light            72"
  },
  {
    "objectID": "chapters/data_analisis.html#desagregaciones",
    "href": "chapters/data_analisis.html#desagregaciones",
    "title": "4  Análisis de datos",
    "section": "4.6 Desagregaciones",
    "text": "4.6 Desagregaciones\n¿Y si quisiéramos ver el porcentaje de personal por sexo para cada institución? Para ese caso vamos a necesitar la función ungroup, que hace exactamente lo opuesto que el group_by, desagrega por la variable seleccionada.\n\npersonal_por_sexo <- df_filtrado %>% \n  mutate(sexo_1 = if_else(sexo == \"M\", \"Hombre\", \"Mujer\")) %>% \n  group_by(institucion, sexo_1) %>% \n  summarise(cantidad = n_distinct(cod_persona)) %>% \n  group_by(institucion) %>% \n  mutate(porcentaje = round(cantidad / sum(cantidad) * 100, 0)) %>% \n  ungroup()\n\npersonal_por_sexo\n\n# A tibble: 8 x 4\n  institucion     sexo_1 cantidad porcentaje\n  <chr>           <chr>     <int>      <dbl>\n1 ASFE            Hombre       82         55\n2 ASFE            Mujer        66         45\n3 Blue Light      Hombre       72         46\n4 Blue Light      Mujer        84         54\n5 RedHat Hospital Hombre       78         50\n6 RedHat Hospital Mujer        79         50\n7 St. Mokaroo     Hombre       91         56\n8 St. Mokaroo     Mujer        71         44\n\n\nSiempre resulta conveniente ejecutar estos ejemplos linea por linea y ver qué resultado va dando, el intentar leer toda la pipeline (así se denomina a una sucesión de acciones unidas por pipes) puede ser confuso si no se está familiarizado aún con las funciones."
  },
  {
    "objectID": "chapters/data_analisis.html#desafío",
    "href": "chapters/data_analisis.html#desafío",
    "title": "4  Análisis de datos",
    "section": "4.7 Desafío",
    "text": "4.7 Desafío\nVamos a querer hacer un análisis que requerirá de todas nuestras herramientas analíticas.\n\nDebe crearse una tabla que muestre la cantidad de personas por institución y sexo.\nTambién debe indicar la cantidad del personal que sea accionista (socio) de la institución, y el porcentaje.\nFinalmente, debe tener una variable que indique si la institución tiene accionistas hombres y mujeres, solo hombres, solo mujeres, o si no tiene accionistas.\n\n\n\nSolución\npersonal_accionista <- df_filtrado %>% \n  mutate(sexo_1 = if_else(sexo == \"M\", \"Hombre\", \"Mujer\")) %>% \n  group_by(institucion, sexo_1) %>% \n  summarise(\n    cantidad_personas = n_distinct(cod_persona),\n    accionistas = sum(socio)\n  ) %>% \n  mutate(tiene_accionistas_h = if_else(accionistas > 0 & sexo_1 == \"Hombre\", 1, 0),\n         tiene_accionistas_m = if_else(accionistas > 0 & sexo_1 == \"Mujer\", 1, 0)) %>% \n  group_by(institucion) %>% \n  mutate(\n    tipo_accionistas = case_when(\n      sum(tiene_accionistas_h) == 1 & sum(tiene_accionistas_m) == 1 ~ \"Tiene accionistas de ambos sexos\",\n      sum(tiene_accionistas_h) == 0 & sum(tiene_accionistas_m) == 1 ~ \"Tiene accionistas solo mujeres\",\n      sum(tiene_accionistas_h) == 1 & sum(tiene_accionistas_m) == 0 ~ \"Tiene accionistas solo hombres\",\n      sum(tiene_accionistas_h) == 0 & sum(tiene_accionistas_m) == 0 ~ \"No tiene accionistas en su personal\"\n    ),\n    porcentaje_accionistas = round(sum(accionistas) / sum(cantidad_personas) * 100, 0)\n  ) %>% \n  ungroup() %>% \n  select(-tiene_accionistas_h, -tiene_accionistas_m) %>% \n  group_by(institucion) %>% \n  summarise(\n    cantidad_personas = sum(cantidad_personas),\n    cantidad_accionistas = sum(accionistas),\n    porcentaje_accionistas = max(porcentaje_accionistas),\n    tipo_accionistas = max(tipo_accionistas)\n  )"
  },
  {
    "objectID": "chapters/data_manipulation.html#desafío",
    "href": "chapters/data_manipulation.html#desafío",
    "title": "5  Manipulación de datos",
    "section": "5.5 Desafío",
    "text": "5.5 Desafío\n\nGenere una tabla que muestre el total de productos vendidos, y el total revenue por año y mes. Elimine los casos en donde haya valores faltantes.\n¿Cuáles han sido, para cada año, los cinco productos menos vendidos? ¿Y los menos rentables?\n\n¿Cuántos días han pasado desde que se vendieron estos productos con respecto a la última fecha registrada?\n\nInvestigue si se vende más caro en la primera mitad del año o en la segunda, averiguando el promedio de venta por unidad. Convierta los valores faltantes del mes en enero.\n\n\n\nPosible solución\n# Ejercicio 1\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date), mes = month(date)) %>% \n  drop_na(any_of(c(\"anio\", \"mes\"))) %>% \n  group_by(anio, mes) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE))\n\n# Ejercico 2\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date)) %>% \n  drop_na(any_of(c(\"anio\", \"product\"))) %>% \n  group_by(anio, product) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>%   arrange(cantidad) %>% \n  head(5)\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date)) %>% \n  drop_na(any_of(c(\"anio\", \"product\"))) %>% \n  group_by(anio, product) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>%   arrange(total_ingreso) %>% \n  head(5)\n\n# Ejercicio 2 parte b\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(anio = year(date)) %>% \n  drop_na(any_of(c(\"anio\", \"product\"))) %>% \n  group_by(anio, product) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>% \n  arrange(total_ingreso) %>% \n  head(1) %>% \n  select(product) %>% \n  left_join(datos, by = 'product') %>% \n  mutate(date = dmy(date), hoy = today()) %>% \n  arrange(desc(date)) %>% \n  mutate(dias_desde_que_se_vendio = interval(date, hoy) %/% days(1)) %>% \n  select(product, dias_desde_que_se_vendio) %>% \n  head()\n\n# Ejercicio 3\n\ndatos %>% \n  mutate(date = dmy(date)) %>% \n  mutate(mes = month(date)) %>%\n  replace_na(list(mes = 1)) %>% \n  mutate(\n    parte_del_anio = case_when(\n      mes < 7 ~ \"Primera parte\",\n      mes > 6 ~ \"Segunda parte\"\n    )\n  ) %>% \n  group_by(parte_del_anio) %>% \n  summarise(cantidad = n(), total_ingreso = sum(revenue, na.rm = TRUE)) %>%\n  mutate(promedio_venta = total_ingreso/cantidad)"
  },
  {
    "objectID": "chapters/cierre.html",
    "href": "chapters/cierre.html",
    "title": "7  Próximos pasos",
    "section": "",
    "text": "El camino de los datos es largo y amplio.\nManejar una herramienta como R para el análisis descriptivo es una habilidad relevante, y conviene ponerla en práctica en base a proyectos. La mejor forma de practicar el uso de una herramienta como R es proponerse solucionar un problema basado en datos, y hacerlo enteramente dentro de la herramienta RStudio.\nMuchas veces necesitamos realizar análisis para generar un informe de situación. Podemos realizar el informe enteramente en R y generar un documento PDF, HTML, o Word mediante el uso de Quarto. Esto es un framework que permite generar documentos dentro de RStudio y que funciona con otros lenguajes además de R, como Python o Julia. Creando un documento en RStudio podemos insertar las tablas o gráficas que querramos juntos con el texto descriptivo del informe, sin necesidad de pasar de una herramienta a otra.\nEn otras ocasiones resulta necesario generar un dashboard dinámico que presente determinada información. Para ello es conveniente usar el framework Shiny, que permite construir tableros interactivos para el usuario dentro de RStudio. Además, se puede posteriormente publicar dentro de una página web para el posterior uso de los usuarios finales. Nada tiene que envidiarle a herramientas como Power BI o Tableau."
  },
  {
    "objectID": "chapters/cierre.html#a-veces-necesitamos-ayuda",
    "href": "chapters/cierre.html#a-veces-necesitamos-ayuda",
    "title": "7  Próximos pasos",
    "section": "7.2 A veces necesitamos ayuda",
    "text": "7.2 A veces necesitamos ayuda\nSin dudas que con un libro o un curso es difícil decir que uno esté capacitado para llevar adelante de forma independiente un proyecto de análisis de datos con R o cualquier herramienta. Es conveniente que dicha tarea sea un trabajo colectivo, y en muchos casos, mentoreado.\nSi sientes que tu o tu organización podrían usar una mano para llevar adelante un proyecto de datos con R, no dudes en contactarme."
  },
  {
    "objectID": "chapters/cierre.html#desafío",
    "href": "chapters/cierre.html#desafío",
    "title": "7  Próximos pasos",
    "section": "7.3 Desafío",
    "text": "7.3 Desafío\nAhora el desafío es tuyo.\n\nToma un proyecto basado en datos y ponte a resolverlo con R y RStudio\nEstudia si dicho proyecto podría beneficiarse de herramientas como Quarto o Shiny, y apréndelas si es necesario.\nPide ayuda o mentoría si crees que el proyecto lo requiere\n\nSi este libro te ayudó en tu camino, me encantaría que algún día me lo mencionaras.\nHasta entonces, ¡éxitos en tu carrera, data analyst!"
  }
]